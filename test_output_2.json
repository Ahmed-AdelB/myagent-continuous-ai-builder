{
  "timestamp": "2025-11-29T06:02:30.253441",
  "total_duration": 955.5448267459869,
  "summary": {
    "total_categories": 3,
    "passed": 0,
    "failed": 3,
    "success_rate": 0.0
  },
  "results": {
    "unit": {
      "category": "unit",
      "status": "FAILED",
      "duration": 913.1644978523254,
      "returncode": 1,
      "stdout": "============================= test session starts ==============================\nplatform darwin -- Python 3.9.6, pytest-8.1.1, pluggy-1.6.0 -- /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/venv/bin/python\ncachedir: .pytest_cache\nrootdir: /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder\nconfigfile: pytest.ini\nplugins: asyncio-0.23.5, anyio-4.12.0, langsmith-0.4.37, cov-4.1.0\nasyncio: mode=strict\ncollecting ... collected 151 items\n\ntests/unit/test_gpt5_p10_causal.py::TestCausalAnalyticsEngine::test_causal_analytics_initialization PASSED [  0%]\ntests/unit/test_gpt5_p10_causal.py::TestCausalAnalyticsEngine::test_variable_management PASSED [  1%]\ntests/unit/test_gpt5_p10_causal.py::TestCausalAnalyticsEngine::test_causal_relationship_management PASSED [  1%]\ntests/unit/test_gpt5_p10_causal.py::TestCausalAnalyticsEngine::test_causal_relationship_validation PASSED [  2%]\ntests/unit/test_gpt5_p10_causal.py::TestCausalAnalyticsEngine::test_correlation_calculation PASSED [  3%]\ntests/unit/test_gpt5_p10_causal.py::TestCausalAnalyticsEngine::test_confounder_identification PASSED [  3%]\ntests/unit/test_gpt5_p10_causal.py::TestCausalAnalyticsEngine::test_causal_discovery FAILED [  4%]\ntests/unit/test_gpt5_p10_causal.py::TestCausalAnalyticsEngine::test_experiment_design PASSED [  5%]\ntests/unit/test_gpt5_p10_causal.py::TestCausalAnalyticsEngine::test_sample_size_calculation PASSED [  5%]\ntests/unit/test_gpt5_p10_causal.py::TestCausalAnalyticsEngine::test_experiment_execution PASSED [  6%]\ntests/unit/test_gpt5_p10_causal.py::TestCausalAnalyticsEngine::test_treatment_effect_estimation_backdoor PASSED [  7%]\ntests/unit/test_gpt5_p10_causal.py::TestCausalAnalyticsEngine::test_treatment_effect_estimation_iv PASSED [  7%]\ntests/unit/test_gpt5_p10_causal.py::TestCausalAnalyticsEngine::test_treatment_effect_estimation_propensity_score PASSED [  8%]\ntests/unit/test_gpt5_p10_causal.py::TestCausalAnalyticsEngine::test_counterfactual_analysis PASSED [  9%]\ntests/unit/test_gpt5_p10_causal.py::TestCausalAnalyticsEngine::test_mediation_analysis PASSED [  9%]\ntests/unit/test_gpt5_p10_causal.py::TestCausalAnalyticsEngine::test_causal_graph_export PASSED [ 10%]\ntests/unit/test_gpt5_p10_causal.py::TestCausalAnalyticsEngine::test_causal_model_validation PASSED [ 11%]\ntests/unit/test_gpt5_p10_causal.py::TestCausalAnalyticsEngine::test_cycle_detection PASSED [ 11%]\ntests/unit/test_gpt5_p10_causal.py::TestCausalAnalyticsEngine::test_concurrent_causal_operations PASSED [ 12%]\ntests/unit/test_gpt5_p10_causal.py::TestCausalAnalyticsEngine::test_large_scale_causal_analysis FAILED [ 13%]\ntests/unit/test_gpt5_p10_causal.py::TestCausalInferenceMethods::test_causal_variables_from_test_data PASSED [ 13%]\ntests/unit/test_gpt5_p10_causal.py::TestCausalInferenceMethods::test_causal_methods_from_test_data PASSED [ 14%]\ntests/unit/test_gpt5_p10_causal.py::TestCausalInferenceMethods::test_sample_interventions_from_test_data PASSED [ 15%]\ntests/unit/test_gpt5_p4_memory.py::TestHierarchicalMemoryPyramid::test_initialization FAILED [ 15%]\ntests/unit/test_gpt5_p4_memory.py::TestHierarchicalMemoryPyramid::test_store_memory_working_tier FAILED [ 16%]\ntests/unit/test_gpt5_p4_memory.py::TestHierarchicalMemoryPyramid::test_store_multiple_memories FAILED [ 17%]\ntests/unit/test_gpt5_p4_memory.py::TestHierarchicalMemoryPyramid::test_retrieve_memory_by_id FAILED [ 17%]\ntests/unit/test_gpt5_p4_memory.py::TestHierarchicalMemoryPyramid::test_search_memories_by_content FAILED [ 18%]\ntests/unit/test_gpt5_p4_memory.py::TestHierarchicalMemoryPyramid::test_search_memories_by_type FAILED [ 19%]\ntests/unit/test_gpt5_p4_memory.py::TestHierarchicalMemoryPyramid::test_memory_consolidation_by_count FAILED [ 19%]\ntests/unit/test_gpt5_p4_memory.py::TestHierarchicalMemoryPyramid::test_memory_consolidation_by_time FAILED [ 20%]\ntests/unit/test_gpt5_p4_memory.py::TestHierarchicalMemoryPyramid::test_memory_compression FAILED [ 21%]\ntests/unit/test_gpt5_p4_memory.py::TestHierarchicalMemoryPyramid::test_memory_importance_scoring FAILED [ 21%]\ntests/unit/test_gpt5_p4_memory.py::TestHierarchicalMemoryPyramid::test_memory_relationships FAILED [ 22%]\ntests/unit/test_gpt5_p4_memory.py::TestHierarchicalMemoryPyramid::test_memory_statistics FAILED [ 23%]\ntests/unit/test_gpt5_p4_memory.py::TestHierarchicalMemoryPyramid::test_memory_cleanup FAILED [ 23%]\ntests/unit/test_gpt5_p4_memory.py::TestHierarchicalMemoryPyramid::test_memory_export_import FAILED [ 24%]\ntests/unit/test_gpt5_p4_memory.py::TestHierarchicalMemoryPyramid::test_concurrent_memory_operations FAILED [ 25%]\ntests/unit/test_gpt5_p4_memory.py::TestHierarchicalMemoryPyramid::test_memory_tier_promotion FAILED [ 25%]\ntests/unit/test_gpt5_p4_memory.py::TestHierarchicalMemoryPyramid::test_memory_pyramid_performance FAILED [ 26%]\ntests/unit/test_gpt5_p4_memory.py::TestMemoryNode::test_memory_node_creation FAILED [ 27%]\ntests/unit/test_gpt5_p4_memory.py::TestMemoryNode::test_memory_node_serialization FAILED [ 27%]\ntests/unit/test_gpt5_p4_memory.py::TestMemoryNode::test_memory_node_update_access FAILED [ 28%]\ntests/unit/test_gpt5_p4_memory.py::TestMemoryNode::test_memory_node_importance_decay FAILED [ 29%]\ntests/unit/test_gpt5_p4_memory.py::TestMemoryTierEnums::test_memory_tier_enum PASSED [ 29%]\ntests/unit/test_gpt5_p4_memory.py::TestMemoryTierEnums::test_memory_type_enum FAILED [ 30%]\ntests/unit/test_gpt5_p5_security.py::TestSecurityComplianceScanner::test_scanner_initialization FAILED [ 31%]\ntests/unit/test_gpt5_p5_security.py::TestSecurityComplianceScanner::test_sql_injection_detection FAILED [ 31%]\ntests/unit/test_gpt5_p5_security.py::TestSecurityComplianceScanner::test_xss_vulnerability_detection FAILED [ 32%]\ntests/unit/test_gpt5_p5_security.py::TestSecurityComplianceScanner::test_hardcoded_secrets_detection FAILED [ 33%]\ntests/unit/test_gpt5_p5_security.py::TestSecurityComplianceScanner::test_insecure_crypto_detection FAILED [ 33%]\ntests/unit/test_gpt5_p5_security.py::TestSecurityComplianceScanner::test_path_traversal_detection FAILED [ 34%]\ntests/unit/test_gpt5_p5_security.py::TestSecurityComplianceScanner::test_scan_file FAILED [ 35%]\ntests/unit/test_gpt5_p5_security.py::TestSecurityComplianceScanner::test_scan_directory FAILED [ 35%]\ntests/unit/test_gpt5_p5_security.py::TestSecurityComplianceScanner::test_owasp_compliance_check FAILED [ 36%]\ntests/unit/test_gpt5_p5_security.py::TestSecurityComplianceScanner::test_gdpr_compliance_check FAILED [ 37%]\ntests/unit/test_gpt5_p5_security.py::TestSecurityComplianceScanner::test_pci_dss_compliance_check FAILED [ 37%]\ntests/unit/test_gpt5_p5_security.py::TestSecurityComplianceScanner::test_risk_assessment FAILED [ 38%]\ntests/unit/test_gpt5_p5_security.py::TestSecurityComplianceScanner::test_security_report_generation FAILED [ 39%]\ntests/unit/test_gpt5_p5_security.py::TestSecurityComplianceScanner::test_false_positive_handling FAILED [ 39%]\ntests/unit/test_gpt5_p5_security.py::TestSecurityComplianceScanner::test_vulnerability_pattern_updates FAILED [ 40%]\ntests/unit/test_gpt5_p5_security.py::TestSecurityComplianceScanner::test_scan_performance FAILED [ 41%]\ntests/unit/test_gpt5_p5_security.py::TestSecurityComplianceScanner::test_concurrent_scanning FAILED [ 41%]\ntests/unit/test_gpt5_p5_security.py::TestSecurityVulnerability::test_security_issue_creation FAILED [ 42%]\ntests/unit/test_gpt5_p5_security.py::TestSecurityVulnerability::test_security_issue_serialization FAILED [ 43%]\ntests/unit/test_gpt5_p5_security.py::TestSecurityLevelEnum::test_risk_level_values FAILED [ 43%]\ntests/unit/test_gpt5_p5_security.py::TestSecurityLevelEnum::test_risk_level_ordering PASSED [ 44%]\ntests/unit/test_gpt5_p5_security.py::TestVulnerabilityTypeEnum::test_vulnerability_types_exist FAILED [ 45%]\ntests/unit/test_gpt5_p5_security.py::TestVulnerabilityTypeEnum::test_vulnerability_type_values FAILED [ 45%]\ntests/unit/test_gpt5_p6_healing.py::TestSelfHealingOrchestrator::test_monitoring_lifecycle PASSED [ 46%]\ntests/unit/test_gpt5_p6_healing.py::TestSelfHealingOrchestrator::test_system_metrics_collection PASSED [ 47%]\ntests/unit/test_gpt5_p6_healing.py::TestSelfHealingOrchestrator::test_metrics_health_assessment PASSED [ 47%]\ntests/unit/test_gpt5_p6_healing.py::TestSelfHealingOrchestrator::test_anomaly_detection_healthy_system PASSED [ 48%]\ntests/unit/test_gpt5_p6_healing.py::TestSelfHealingOrchestrator::test_anomaly_detection_unhealthy_system PASSED [ 49%]\ntests/unit/test_gpt5_p6_healing.py::TestSelfHealingOrchestrator::test_health_trends_analysis_insufficient_data PASSED [ 49%]\ntests/unit/test_gpt5_p6_healing.py::TestSelfHealingOrchestrator::test_health_trends_analysis_with_data PASSED [ 50%]\ntests/unit/test_gpt5_p6_healing.py::TestSelfHealingOrchestrator::test_failure_pattern_identification PASSED [ 50%]\ntests/unit/test_gpt5_p6_healing.py::TestSelfHealingOrchestrator::test_repair_action_execution_success PASSED [ 51%]\ntests/unit/test_gpt5_p6_healing.py::TestSelfHealingOrchestrator::test_repair_action_execution_failure FAILED [ 52%]\ntests/unit/test_gpt5_p6_healing.py::TestSelfHealingOrchestrator::test_recovery_validation_success PASSED [ 52%]\ntests/unit/test_gpt5_p6_healing.py::TestSelfHealingOrchestrator::test_recovery_validation_repair_not_found PASSED [ 53%]\ntests/unit/test_gpt5_p6_healing.py::TestSelfHealingOrchestrator::test_performance_optimization_database PASSED [ 54%]\ntests/unit/test_gpt5_p6_healing.py::TestSelfHealingOrchestrator::test_performance_optimization_system_wide PASSED [ 54%]\ntests/unit/test_gpt5_p6_healing.py::TestSelfHealingOrchestrator::test_health_report_generation_healthy PASSED [ 55%]\ntests/unit/test_gpt5_p6_healing.py::TestSelfHealingOrchestrator::test_health_report_generation_degraded PASSED [ 56%]\ntests/unit/test_gpt5_p6_healing.py::TestSelfHealingOrchestrator::test_concurrent_repair_actions PASSED [ 56%]\ntests/unit/test_gpt5_p6_healing.py::TestSelfHealingOrchestrator::test_repair_action_rollback_capability FAILED [ 57%]\ntests/unit/test_gpt5_p6_healing.py::TestSelfHealingOrchestrator::test_failure_pattern_frequency_tracking PASSED [ 58%]\ntests/unit/test_gpt5_p6_healing.py::TestSelfHealingOrchestrator::test_system_recovery_workflow PASSED [ 58%]\ntests/unit/test_gpt5_p6_healing.py::TestFailurePatternAnalysis::test_failure_pattern_creation PASSED [ 59%]\ntests/unit/test_gpt5_p6_healing.py::TestFailurePatternAnalysis::test_failure_pattern_serialization PASSED [ 60%]\ntests/unit/test_gpt5_p6_healing.py::TestFailurePatternAnalysis::test_failure_scenario_templates PASSED [ 60%]\ntests/unit/test_gpt5_p6_healing.py::TestFailurePatternAnalysis::test_pattern_matching_algorithm PASSED [ 61%]\ntests/unit/test_gpt5_p6_healing.py::TestRepairActionManagement::test_repair_action_creation PASSED [ 62%]\ntests/unit/test_gpt5_p6_healing.py::TestRepairActionManagement::test_repair_action_serialization PASSED [ 62%]\ntests/unit/test_gpt5_p6_healing.py::TestRepairActionManagement::test_repair_action_priority_queue PASSED [ 63%]\ntests/unit/test_gpt5_p6_healing.py::TestRepairActionManagement::test_repair_action_timeout_handling PASSED [ 64%]\ntests/unit/test_gpt5_p6_healing.py::TestSystemResilienceValidation::test_chaos_engineering_network_partition FAILED [ 64%]\ntests/unit/test_gpt5_p6_healing.py::TestSystemResilienceValidation::test_cascading_failure_detection PASSED [ 65%]\ntests/unit/test_gpt5_p6_healing.py::TestSystemResilienceValidation::test_system_load_spike_recovery PASSED [ 66%]\ntests/unit/test_gpt5_p6_healing.py::TestSystemResilienceValidation::test_resource_exhaustion_scenarios PASSED [ 66%]\ntests/unit/test_gpt5_p7_knowledge.py::TestKnowledgeGraphManager::test_knowledge_graph_initialization PASSED [ 67%]\ntests/unit/test_gpt5_p7_knowledge.py::TestKnowledgeGraphManager::test_entity_creation_and_retrieval PASSED [ 68%]\ntests/unit/test_gpt5_p7_knowledge.py::TestKnowledgeGraphManager::test_entity_type_indexing PASSED [ 68%]\ntests/unit/test_gpt5_p7_knowledge.py::TestKnowledgeGraphManager::test_relationship_creation PASSED [ 69%]\ntests/unit/test_gpt5_p7_knowledge.py::TestKnowledgeGraphManager::test_relationship_validation PASSED [ 70%]\ntests/unit/test_gpt5_p7_knowledge.py::TestKnowledgeGraphManager::test_entity_embedding_generation FAILED [ 70%]\ntests/unit/test_gpt5_p7_knowledge.py::TestKnowledgeGraphManager::test_related_entities_retrieval PASSED [ 71%]\ntests/unit/test_gpt5_p7_knowledge.py::TestKnowledgeGraphManager::test_related_entities_with_type_filter PASSED [ 72%]\ntests/unit/test_gpt5_p7_knowledge.py::TestKnowledgeGraphManager::test_semantic_search PASSED [ 72%]\ntests/unit/test_gpt5_p7_knowledge.py::TestKnowledgeGraphManager::test_semantic_search_with_type_filter PASSED [ 73%]\ntests/unit/test_gpt5_p7_knowledge.py::TestKnowledgeGraphManager::test_pattern_detection_code_patterns PASSED [ 74%]\ntests/unit/test_gpt5_p7_knowledge.py::TestKnowledgeGraphManager::test_pattern_detection_dependency_patterns PASSED [ 74%]\ntests/unit/test_gpt5_p7_knowledge.py::TestKnowledgeGraphManager::test_code_analysis PASSED [ 75%]\ntests/unit/test_gpt5_p7_knowledge.py::TestKnowledgeGraphManager::test_code_suggestions_generation PASSED [ 76%]\ntests/unit/test_gpt5_p7_knowledge.py::TestKnowledgeGraphManager::test_knowledge_consolidation_similarity_merge PASSED [ 76%]\ntests/unit/test_gpt5_p7_knowledge.py::TestKnowledgeGraphManager::test_graph_export_json_format PASSED [ 77%]\ntests/unit/test_gpt5_p7_knowledge.py::TestKnowledgeGraphManager::test_graph_statistics_calculation PASSED [ 78%]\ntests/unit/test_gpt5_p7_knowledge.py::TestKnowledgeGraphManager::test_multi_depth_relationship_traversal FAILED [ 78%]\ntests/unit/test_gpt5_p7_knowledge.py::TestKnowledgeGraphManager::test_concurrent_graph_operations PASSED [ 79%]\ntests/unit/test_gpt5_p7_knowledge.py::TestKnowledgeGraphManager::test_large_scale_graph_performance FAILED [ 80%]\ntests/unit/test_gpt5_p7_knowledge.py::TestSemanticQueryProcessing::test_semantic_query_creation PASSED [ 80%]\ntests/unit/test_gpt5_p7_knowledge.py::TestSemanticQueryProcessing::test_complex_semantic_queries PASSED [ 81%]\ntests/unit/test_gpt5_p7_knowledge.py::TestSemanticQueryProcessing::test_contextual_code_understanding PASSED [ 82%]\ntests/unit/test_gpt5_p7_knowledge.py::TestKnowledgeTransferAndLearning::test_cross_project_pattern_recognition FAILED [ 82%]\ntests/unit/test_gpt5_p7_knowledge.py::TestKnowledgeTransferAndLearning::test_knowledge_evolution_tracking PASSED [ 83%]\ntests/unit/test_gpt5_p7_knowledge.py::TestKnowledgeTransferAndLearning::test_solution_pattern_generalization FAILED [ 84%]\ntests/unit/test_gpt5_p9_deployment.py::TestDeploymentOrchestrator::test_deployment_orchestrator_initialization PASSED [ 84%]\ntests/unit/test_gpt5_p9_deployment.py::TestDeploymentOrchestrator::test_deployment_config_validation FAILED [ 85%]\ntests/unit/test_gpt5_p9_deployment.py::TestDeploymentOrchestrator::test_quality_gate_evaluation PASSED [ 86%]\ntests/unit/test_gpt5_p9_deployment.py::TestDeploymentOrchestrator::test_deployment_creation FAILED [ 86%]\ntests/unit/test_gpt5_p9_deployment.py::TestDeploymentOrchestrator::test_deployment_creation_with_invalid_config FAILED [ 87%]\ntests/unit/test_gpt5_p9_deployment.py::TestDeploymentOrchestrator::test_deployment_pipeline_execution_success FAILED [ 88%]\ntests/unit/test_gpt5_p9_deployment.py::TestDeploymentOrchestrator::test_deployment_pipeline_stages PASSED [ 88%]\ntests/unit/test_gpt5_p9_deployment.py::TestDeploymentOrchestrator::test_individual_stage_execution PASSED [ 89%]\ntests/unit/test_gpt5_p9_deployment.py::TestDeploymentOrchestrator::test_quality_gates_integration FAILED [ 90%]\ntests/unit/test_gpt5_p9_deployment.py::TestDeploymentOrchestrator::test_deployment_rollback_on_failure FAILED [ 90%]\ntests/unit/test_gpt5_p9_deployment.py::TestDeploymentOrchestrator::test_deployment_cancellation FAILED [ 91%]\ntests/unit/test_gpt5_p9_deployment.py::TestDeploymentOrchestrator::test_infrastructure_provisioning PASSED [ 92%]\ntests/unit/test_gpt5_p9_deployment.py::TestDeploymentOrchestrator::test_deployment_scaling FAILED [ 92%]\ntests/unit/test_gpt5_p9_deployment.py::TestDeploymentOrchestrator::test_deployment_metrics_collection FAILED [ 93%]\ntests/unit/test_gpt5_p9_deployment.py::TestDeploymentOrchestrator::test_secrets_management PASSED [ 94%]\ntests/unit/test_gpt5_p9_deployment.py::TestDeploymentOrchestrator::test_deployment_status_retrieval FAILED [ 94%]\ntests/unit/test_gpt5_p9_deployment.py::TestDeploymentOrchestrator::test_deployment_with_different_strategies FAILED [ 95%]\ntests/unit/test_gpt5_p9_deployment.py::TestDeploymentOrchestrator::test_concurrent_deployments FAILED [ 96%]\ntests/unit/test_gpt5_p9_deployment.py::TestDeploymentOrchestrator::test_deployment_timeout_handling FAILED [ 96%]\ntests/unit/test_gpt5_p9_deployment.py::TestDeploymentOrchestrator::test_post_deployment_validation FAILED [ 97%]\ntests/unit/test_gpt5_p9_deployment.py::TestDeploymentPipelineIntegration::test_pipeline_stages_from_test_data FAILED [ 98%]\ntests/unit/test_gpt5_p9_deployment.py::TestDeploymentPipelineIntegration::test_quality_gates_from_test_data FAILED [ 98%]\ntests/unit/test_gpt5_p9_deployment.py::TestDeploymentPipelineIntegration::test_deployment_strategies_from_test_data FAILED [ 99%]\ntests/unit/test_gpt5_p9_deployment.py::TestDeploymentPipelineIntegration::test_multi_environment_deployment_workflow FAILED [100%]\n\n=================================== FAILURES ===================================\n_______________ TestCausalAnalyticsEngine.test_causal_discovery ________________\n\nself = <test_gpt5_p10_causal.TestCausalAnalyticsEngine object at 0x134ce5760>\ncausal_analytics = <test_gpt5_p10_causal.MockCausalAnalyticsEngine object at 0x134ed4f70>\nsample_data = [{'code_complexity': 8.2, 'code_refactoring': 1, 'developer_experience': 5, 'performance_improvement': 25.5}, {'code_c....9}, {'code_complexity': 11.8, 'code_refactoring': 0, 'developer_experience': 4, 'performance_improvement': 12.4}, ...]\n\n    @pytest.mark.asyncio\n    async def test_causal_discovery(self, causal_analytics, sample_data):\n        \"\"\"Test causal relationship discovery from data\"\"\"\n        await causal_analytics.initialize()\n    \n>       discovered_relationships = await causal_analytics.discover_causal_relationships(\n            sample_data,\n            CausalMethodType.BACKDOOR\n        )\n\ntests/unit/test_gpt5_p10_causal.py:1316: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/unit/test_gpt5_p10_causal.py:257: in discover_causal_relationships\n    await self.add_causal_relationship(relationship)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <test_gpt5_p10_causal.MockCausalAnalyticsEngine object at 0x134ed4f70>\nrelationship = CausalRelationship(relationship_id='discovered_0580ee', cause_variable_id='code_refactoring', effect_variable_id='perf..._sources=['backdoor_analysis_dataset_89434cb1'], confounders=['code_complexity', 'developer_experience'], mediators=[])\n\n    async def add_causal_relationship(self, relationship: CausalRelationship) -> str:\n        \"\"\"Add causal relationship between variables\"\"\"\n        if not relationship.relationship_id:\n            relationship.relationship_id = f\"rel_{uuid.uuid4().hex[:8]}\"\n    \n        # Validate variables exist\n        if (relationship.cause_variable_id not in self.variables or\n            relationship.effect_variable_id not in self.variables):\n>           raise ValueError(\"Cause or effect variable does not exist\")\nE           ValueError: Cause or effect variable does not exist\n\ntests/unit/test_gpt5_p10_causal.py:207: ValueError\n__________ TestCausalAnalyticsEngine.test_large_scale_causal_analysis __________\n\nself = <test_gpt5_p10_causal.TestCausalAnalyticsEngine object at 0x134ce52b0>\ncausal_analytics = <test_gpt5_p10_causal.MockCausalAnalyticsEngine object at 0x1351b4f70>\n\n    @pytest.mark.asyncio\n    async def test_large_scale_causal_analysis(self, causal_analytics):\n        \"\"\"Test causal analysis with larger datasets\"\"\"\n        await causal_analytics.initialize()\n    \n        # Generate larger dataset\n        large_data = []\n        for i in range(1000):\n            large_data.append({\n                \"treatment\": i % 2,\n                \"outcome\": 50 + (i % 2) * 10 + (i % 100) * 0.1,\n                \"confounder1\": i % 10,\n                \"confounder2\": (i % 5) * 2.5\n            })\n    \n        # Test causal discovery on large dataset\n        start_time = asyncio.get_event_loop().time()\n>       discovered_relationships = await causal_analytics.discover_causal_relationships(large_data)\n\ntests/unit/test_gpt5_p10_causal.py:1680: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/unit/test_gpt5_p10_causal.py:257: in discover_causal_relationships\n    await self.add_causal_relationship(relationship)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <test_gpt5_p10_causal.MockCausalAnalyticsEngine object at 0x1351b4f70>\nrelationship = CausalRelationship(relationship_id='discovered_9562c8', cause_variable_id='confounder1', effect_variable_id='confounde...5, confidence=0.692365963917331, evidence_sources=['backdoor_analysis_dataset_69478734'], confounders=[], mediators=[])\n\n    async def add_causal_relationship(self, relationship: CausalRelationship) -> str:\n        \"\"\"Add causal relationship between variables\"\"\"\n        if not relationship.relationship_id:\n            relationship.relationship_id = f\"rel_{uuid.uuid4().hex[:8]}\"\n    \n        # Validate variables exist\n        if (relationship.cause_variable_id not in self.variables or\n            relationship.effect_variable_id not in self.variables):\n>           raise ValueError(\"Cause or effect variable does not exist\")\nE           ValueError: Cause or effect variable does not exist\n\ntests/unit/test_gpt5_p10_causal.py:207: ValueError\n______________ TestHierarchicalMemoryPyramid.test_initialization _______________\n\nself = <test_gpt5_p4_memory.TestHierarchicalMemoryPyramid object at 0x134d322b0>\ntemp_database = '/var/folders/gc/cjnggvbd1bdgsblrng_h4mf40000gn/T/tmpodi2mmm_.db'\n\n    @pytest.mark.asyncio\n    async def test_initialization(self, temp_database):\n        \"\"\"Test memory pyramid initialization\"\"\"\n>       pyramid = HierarchicalMemoryPyramid(database_path=temp_database)\nE       TypeError: __init__() got an unexpected keyword argument 'database_path'\n\ntests/unit/test_gpt5_p4_memory.py:40: TypeError\n_________ TestHierarchicalMemoryPyramid.test_store_memory_working_tier _________\n\nself = <test_gpt5_p4_memory.TestHierarchicalMemoryPyramid object at 0x134d17370>\nmemory_pyramid = <async_generator object TestHierarchicalMemoryPyramid.memory_pyramid at 0x1351c79d0>\n\n    @pytest.mark.asyncio\n    async def test_store_memory_working_tier(self, memory_pyramid):\n        \"\"\"Test storing memory in working tier\"\"\"\n        content = \"User requested fibonacci function implementation\"\n>       memory_type = MemoryType.USER_REQUEST\n\ntests/unit/test_gpt5_p4_memory.py:61: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ncls = <enum 'MemoryType'>, name = 'USER_REQUEST'\n\n    def __getattr__(cls, name):\n        \"\"\"\n        Return the enum member matching `name`\n    \n        We use __getattr__ instead of descriptors or inserting into the enum\n        class' __dict__ in order to support `name` and `value` being both\n        properties for enum members (which live in the class' __dict__) and\n        enum members themselves.\n        \"\"\"\n        if _is_dunder(name):\n            raise AttributeError(name)\n        try:\n            return cls._member_map_[name]\n        except KeyError:\n>           raise AttributeError(name) from None\nE           AttributeError: USER_REQUEST\n\n/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/enum.py:429: AttributeError\n__________ TestHierarchicalMemoryPyramid.test_store_multiple_memories __________\n\nself = <test_gpt5_p4_memory.TestHierarchicalMemoryPyramid object at 0x134ceb040>\nmemory_pyramid = <async_generator object TestHierarchicalMemoryPyramid.memory_pyramid at 0x134fdfd30>\n\n    @pytest.mark.asyncio\n    async def test_store_multiple_memories(self, memory_pyramid):\n        \"\"\"Test storing multiple memories in different tiers\"\"\"\n        memories = [\n            {\n                \"content\": \"User request for calculator\",\n>               \"memory_type\": MemoryType.USER_REQUEST,\n                \"importance\": 0.7,\n                \"tier\": MemoryTier.WORKING\n            },\n            {\n                \"content\": \"Implemented basic calculator class\",\n                \"memory_type\": MemoryType.IMPLEMENTATION,\n                \"importance\": 0.8,\n                \"tier\": MemoryTier.SHORT_TERM\n            },\n            {\n                \"content\": \"Performance optimization applied\",\n                \"memory_type\": MemoryType.OPTIMIZATION,\n                \"importance\": 0.9,\n                \"tier\": MemoryTier.LONG_TERM\n            }\n        ]\n\ntests/unit/test_gpt5_p4_memory.py:84: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ncls = <enum 'MemoryType'>, name = 'USER_REQUEST'\n\n    def __getattr__(cls, name):\n        \"\"\"\n        Return the enum member matching `name`\n    \n        We use __getattr__ instead of descriptors or inserting into the enum\n        class' __dict__ in order to support `name` and `value` being both\n        properties for enum members (which live in the class' __dict__) and\n        enum members themselves.\n        \"\"\"\n        if _is_dunder(name):\n            raise AttributeError(name)\n        try:\n            return cls._member_map_[name]\n        except KeyError:\n>           raise AttributeError(name) from None\nE           AttributeError: USER_REQUEST\n\n/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/enum.py:429: AttributeError\n___________ TestHierarchicalMemoryPyramid.test_retrieve_memory_by_id ___________\n\nself = <test_gpt5_p4_memory.TestHierarchicalMemoryPyramid object at 0x134d323d0>\nmemory_pyramid = <async_generator object TestHierarchicalMemoryPyramid.memory_pyramid at 0x134fdfc10>\n\n    @pytest.mark.asyncio\n    async def test_retrieve_memory_by_id(self, memory_pyramid):\n        \"\"\"Test retrieving specific memory by ID\"\"\"\n        content = \"Test memory for retrieval\"\n>       memory_type = MemoryType.DECISION\n\ntests/unit/test_gpt5_p4_memory.py:129: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ncls = <enum 'MemoryType'>, name = 'DECISION'\n\n    def __getattr__(cls, name):\n        \"\"\"\n        Return the enum member matching `name`\n    \n        We use __getattr__ instead of descriptors or inserting into the enum\n        class' __dict__ in order to support `name` and `value` being both\n        properties for enum members (which live in the class' __dict__) and\n        enum members themselves.\n        \"\"\"\n        if _is_dunder(name):\n            raise AttributeError(name)\n        try:\n            return cls._member_map_[name]\n        except KeyError:\n>           raise AttributeError(name) from None\nE           AttributeError: DECISION\n\n/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/enum.py:429: AttributeError\n________ TestHierarchicalMemoryPyramid.test_search_memories_by_content _________\n\nself = <test_gpt5_p4_memory.TestHierarchicalMemoryPyramid object at 0x134d32670>\nmemory_pyramid = <async_generator object TestHierarchicalMemoryPyramid.memory_pyramid at 0x134fd9f70>\n\n    @pytest.mark.asyncio\n    async def test_search_memories_by_content(self, memory_pyramid):\n        \"\"\"Test searching memories by content\"\"\"\n        # Store test memories\n        test_memories = [\n            \"Implement fibonacci function using recursion\",\n            \"Optimize fibonacci with memoization\",\n            \"Create unit tests for calculator module\",\n            \"Debug performance issues in sorting algorithm\"\n        ]\n    \n        for content in test_memories:\n>           await memory_pyramid.store_memory(\n                content=content,\n                memory_type=MemoryType.IMPLEMENTATION,\n                importance=0.7\n            )\nE           AttributeError: 'async_generator' object has no attribute 'store_memory'\n\ntests/unit/test_gpt5_p4_memory.py:158: AttributeError\n__________ TestHierarchicalMemoryPyramid.test_search_memories_by_type __________\n\nself = <test_gpt5_p4_memory.TestHierarchicalMemoryPyramid object at 0x134d32910>\nmemory_pyramid = <async_generator object TestHierarchicalMemoryPyramid.memory_pyramid at 0x134fd93a0>\n\n    @pytest.mark.asyncio\n    async def test_search_memories_by_type(self, memory_pyramid):\n        \"\"\"Test searching memories by type\"\"\"\n        # Store memories of different types\n        memories_by_type = [\n>           (\"User wants calculator\", MemoryType.USER_REQUEST),\n            (\"Implemented Calculator class\", MemoryType.IMPLEMENTATION),\n            (\"Decided to use Python\", MemoryType.DECISION),\n            (\"Fixed division by zero bug\", MemoryType.BUG_FIX),\n            (\"Optimized algorithm performance\", MemoryType.OPTIMIZATION)\n        ]\n\ntests/unit/test_gpt5_p4_memory.py:181: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ncls = <enum 'MemoryType'>, name = 'USER_REQUEST'\n\n    def __getattr__(cls, name):\n        \"\"\"\n        Return the enum member matching `name`\n    \n        We use __getattr__ instead of descriptors or inserting into the enum\n        class' __dict__ in order to support `name` and `value` being both\n        properties for enum members (which live in the class' __dict__) and\n        enum members themselves.\n        \"\"\"\n        if _is_dunder(name):\n            raise AttributeError(name)\n        try:\n            return cls._member_map_[name]\n        except KeyError:\n>           raise AttributeError(name) from None\nE           AttributeError: USER_REQUEST\n\n/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/enum.py:429: AttributeError\n_______ TestHierarchicalMemoryPyramid.test_memory_consolidation_by_count _______\n\nself = <test_gpt5_p4_memory.TestHierarchicalMemoryPyramid object at 0x134d32bb0>\nmemory_pyramid = <async_generator object TestHierarchicalMemoryPyramid.memory_pyramid at 0x134fd94c0>\n\n    @pytest.mark.asyncio\n    async def test_memory_consolidation_by_count(self, memory_pyramid):\n        \"\"\"Test automatic memory consolidation when working memory is full\"\"\"\n        # Set low threshold for testing\n        pyramid = memory_pyramid\n>       pyramid.working_memory_threshold = 3\nE       AttributeError: 'async_generator' object has no attribute 'working_memory_threshold'\n\ntests/unit/test_gpt5_p4_memory.py:209: AttributeError\n_______ TestHierarchicalMemoryPyramid.test_memory_consolidation_by_time ________\n\nself = <test_gpt5_p4_memory.TestHierarchicalMemoryPyramid object at 0x134d32e50>\nmemory_pyramid = <async_generator object TestHierarchicalMemoryPyramid.memory_pyramid at 0x134fd9940>\n\n    @pytest.mark.asyncio\n    async def test_memory_consolidation_by_time(self, memory_pyramid):\n        \"\"\"Test time-based memory consolidation\"\"\"\n        pyramid = memory_pyramid\n    \n        # Create old memory (simulate)\n        old_content = \"Old memory for consolidation test\"\n>       memory_id = await pyramid.store_memory(\n            content=old_content,\n            memory_type=MemoryType.IMPLEMENTATION,\n            importance=0.6\n        )\nE       AttributeError: 'async_generator' object has no attribute 'store_memory'\n\ntests/unit/test_gpt5_p4_memory.py:238: AttributeError\n____________ TestHierarchicalMemoryPyramid.test_memory_compression _____________\n\nself = <test_gpt5_p4_memory.TestHierarchicalMemoryPyramid object at 0x134d38130>\nmemory_pyramid = <async_generator object TestHierarchicalMemoryPyramid.memory_pyramid at 0x134fd9ca0>\n\n    @pytest.mark.asyncio\n    async def test_memory_compression(self, memory_pyramid):\n        \"\"\"Test memory compression for archive tier\"\"\"\n        pyramid = memory_pyramid\n    \n        # Create memories for compression\n        related_memories = [\n            \"Implemented fibonacci function\",\n            \"Added memoization to fibonacci\",\n            \"Optimized fibonacci performance\",\n            \"Fixed fibonacci edge cases\"\n        ]\n    \n        memory_ids = []\n        for content in related_memories:\n>           memory_id = await pyramid.store_memory(\n                content=content,\n                memory_type=MemoryType.IMPLEMENTATION,\n                importance=0.7,\n                tier=MemoryTier.LONG_TERM\n            )\nE           AttributeError: 'async_generator' object has no attribute 'store_memory'\n\ntests/unit/test_gpt5_p4_memory.py:278: AttributeError\n_________ TestHierarchicalMemoryPyramid.test_memory_importance_scoring _________\n\nself = <test_gpt5_p4_memory.TestHierarchicalMemoryPyramid object at 0x134d383d0>\nmemory_pyramid = <async_generator object TestHierarchicalMemoryPyramid.memory_pyramid at 0x134fd9940>\n\n    @pytest.mark.asyncio\n    async def test_memory_importance_scoring(self, memory_pyramid):\n        \"\"\"Test memory importance calculation and ranking\"\"\"\n        # Store memories with different characteristics\n        memories = [\n            {\n                \"content\": \"Critical security vulnerability found\",\n>               \"memory_type\": MemoryType.BUG_FIX,\n                \"importance\": 0.95,\n                \"access_count\": 10\n            },\n            {\n                \"content\": \"Minor UI improvement suggestion\",\n                \"memory_type\": MemoryType.IMPROVEMENT,\n                \"importance\": 0.3,\n                \"access_count\": 1\n            },\n            {\n                \"content\": \"Core algorithm implementation\",\n                \"memory_type\": MemoryType.IMPLEMENTATION,\n                \"importance\": 0.8,\n                \"access_count\": 5\n            }\n        ]\n\ntests/unit/test_gpt5_p4_memory.py:308: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ncls = <enum 'MemoryType'>, name = 'BUG_FIX'\n\n    def __getattr__(cls, name):\n        \"\"\"\n        Return the enum member matching `name`\n    \n        We use __getattr__ instead of descriptors or inserting into the enum\n        class' __dict__ in order to support `name` and `value` being both\n        properties for enum members (which live in the class' __dict__) and\n        enum members themselves.\n        \"\"\"\n        if _is_dunder(name):\n            raise AttributeError(name)\n        try:\n            return cls._member_map_[name]\n        except KeyError:\n>           raise AttributeError(name) from None\nE           AttributeError: BUG_FIX\n\n/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/enum.py:429: AttributeError\n___________ TestHierarchicalMemoryPyramid.test_memory_relationships ____________\n\nself = <test_gpt5_p4_memory.TestHierarchicalMemoryPyramid object at 0x134d38670>\nmemory_pyramid = <async_generator object TestHierarchicalMemoryPyramid.memory_pyramid at 0x1352640d0>\n\n    @pytest.mark.asyncio\n    async def test_memory_relationships(self, memory_pyramid):\n        \"\"\"Test memory relationship tracking\"\"\"\n        # Create parent memory\n>       parent_id = await memory_pyramid.store_memory(\n            content=\"User request for calculator application\",\n            memory_type=MemoryType.USER_REQUEST,\n            importance=0.8\n        )\nE       AttributeError: 'async_generator' object has no attribute 'store_memory'\n\ntests/unit/test_gpt5_p4_memory.py:353: AttributeError\n_____________ TestHierarchicalMemoryPyramid.test_memory_statistics _____________\n\nself = <test_gpt5_p4_memory.TestHierarchicalMemoryPyramid object at 0x134d38910>\nmemory_pyramid = <async_generator object TestHierarchicalMemoryPyramid.memory_pyramid at 0x1352643a0>\n\n    @pytest.mark.asyncio\n    async def test_memory_statistics(self, memory_pyramid):\n        \"\"\"Test memory usage statistics\"\"\"\n        # Add various memories\n        for i in range(10):\n>           await memory_pyramid.store_memory(\n                content=f\"Test memory {i}\",\n                memory_type=MemoryType.IMPLEMENTATION,\n                importance=0.5 + (i * 0.05),\n                tier=MemoryTier.WORKING if i < 3 else MemoryTier.SHORT_TERM\n            )\nE           AttributeError: 'async_generator' object has no attribute 'store_memory'\n\ntests/unit/test_gpt5_p4_memory.py:390: AttributeError\n______________ TestHierarchicalMemoryPyramid.test_memory_cleanup _______________\n\nself = <test_gpt5_p4_memory.TestHierarchicalMemoryPyramid object at 0x134d38bb0>\nmemory_pyramid = <async_generator object TestHierarchicalMemoryPyramid.memory_pyramid at 0x1352645e0>\n\n    @pytest.mark.asyncio\n    async def test_memory_cleanup(self, memory_pyramid):\n        \"\"\"Test memory cleanup and garbage collection\"\"\"\n        # Create low-importance memories\n        low_importance_ids = []\n        for i in range(5):\n>           memory_id = await memory_pyramid.store_memory(\n                content=f\"Low importance memory {i}\",\n                memory_type=MemoryType.OPTIMIZATION,\n                importance=0.1,\n                tier=MemoryTier.ARCHIVE\n            )\nE           AttributeError: 'async_generator' object has no attribute 'store_memory'\n\ntests/unit/test_gpt5_p4_memory.py:413: AttributeError\n___________ TestHierarchicalMemoryPyramid.test_memory_export_import ____________\n\nself = <test_gpt5_p4_memory.TestHierarchicalMemoryPyramid object at 0x134d38e80>\nmemory_pyramid = <async_generator object TestHierarchicalMemoryPyramid.memory_pyramid at 0x135264940>\ntemp_dir = PosixPath('/var/folders/gc/cjnggvbd1bdgsblrng_h4mf40000gn/T/tmpgnx87_d9')\n\n    @pytest.mark.asyncio\n    async def test_memory_export_import(self, memory_pyramid, temp_dir):\n        \"\"\"Test memory export and import functionality\"\"\"\n        # Store test memories\n        test_memories = [\n>           (\"Memory export test 1\", MemoryType.USER_REQUEST, 0.8),\n            (\"Memory export test 2\", MemoryType.IMPLEMENTATION, 0.7),\n            (\"Memory export test 3\", MemoryType.DECISION, 0.9)\n        ]\n\ntests/unit/test_gpt5_p4_memory.py:448: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ncls = <enum 'MemoryType'>, name = 'USER_REQUEST'\n\n    def __getattr__(cls, name):\n        \"\"\"\n        Return the enum member matching `name`\n    \n        We use __getattr__ instead of descriptors or inserting into the enum\n        class' __dict__ in order to support `name` and `value` being both\n        properties for enum members (which live in the class' __dict__) and\n        enum members themselves.\n        \"\"\"\n        if _is_dunder(name):\n            raise AttributeError(name)\n        try:\n            return cls._member_map_[name]\n        except KeyError:\n>           raise AttributeError(name) from None\nE           AttributeError: USER_REQUEST\n\n/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/enum.py:429: AttributeError\n_______ TestHierarchicalMemoryPyramid.test_concurrent_memory_operations ________\n\nself = <test_gpt5_p4_memory.TestHierarchicalMemoryPyramid object at 0x134d42130>\nmemory_pyramid = <async_generator object TestHierarchicalMemoryPyramid.memory_pyramid at 0x135264430>\n\n    @pytest.mark.asyncio\n    async def test_concurrent_memory_operations(self, memory_pyramid):\n        \"\"\"Test thread-safe concurrent memory operations\"\"\"\n        async def store_memories_batch(batch_id: int):\n            \"\"\"Store a batch of memories concurrently\"\"\"\n            memory_ids = []\n            for i in range(5):\n                memory_id = await memory_pyramid.store_memory(\n                    content=f\"Batch {batch_id} - Memory {i}\",\n                    memory_type=MemoryType.IMPLEMENTATION,\n                    importance=0.5\n                )\n                memory_ids.append(memory_id)\n            return memory_ids\n    \n        # Run concurrent memory storage operations\n        tasks = [store_memories_batch(i) for i in range(3)]\n>       results = await asyncio.gather(*tasks)\n\ntests/unit/test_gpt5_p4_memory.py:512: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nbatch_id = 0\n\n    async def store_memories_batch(batch_id: int):\n        \"\"\"Store a batch of memories concurrently\"\"\"\n        memory_ids = []\n        for i in range(5):\n>           memory_id = await memory_pyramid.store_memory(\n                content=f\"Batch {batch_id} - Memory {i}\",\n                memory_type=MemoryType.IMPLEMENTATION,\n                importance=0.5\n            )\nE           AttributeError: 'async_generator' object has no attribute 'store_memory'\n\ntests/unit/test_gpt5_p4_memory.py:502: AttributeError\n___________ TestHierarchicalMemoryPyramid.test_memory_tier_promotion ___________\n\nself = <test_gpt5_p4_memory.TestHierarchicalMemoryPyramid object at 0x134d38b20>\nmemory_pyramid = <async_generator object TestHierarchicalMemoryPyramid.memory_pyramid at 0x1352645e0>\n\n    @pytest.mark.asyncio\n    async def test_memory_tier_promotion(self, memory_pyramid):\n        \"\"\"Test memory promotion between tiers based on access patterns\"\"\"\n        # Store memory in short-term\n>       memory_id = await memory_pyramid.store_memory(\n            content=\"Frequently accessed implementation detail\",\n            memory_type=MemoryType.IMPLEMENTATION,\n            importance=0.6,\n            tier=MemoryTier.SHORT_TERM\n        )\nE       AttributeError: 'async_generator' object has no attribute 'store_memory'\n\ntests/unit/test_gpt5_p4_memory.py:528: AttributeError\n________ TestHierarchicalMemoryPyramid.test_memory_pyramid_performance _________\n\nself = <test_gpt5_p4_memory.TestHierarchicalMemoryPyramid object at 0x134d38550>\nmemory_pyramid = <async_generator object TestHierarchicalMemoryPyramid.memory_pyramid at 0x135264700>\n\n    @pytest.mark.asyncio\n    async def test_memory_pyramid_performance(self, memory_pyramid):\n        \"\"\"Test memory pyramid performance with large dataset\"\"\"\n        import time\n    \n        # Store large number of memories\n        start_time = time.time()\n        memory_ids = []\n    \n        for i in range(100):\n>           memory_id = await memory_pyramid.store_memory(\n                content=f\"Performance test memory {i}\",\n                memory_type=MemoryType.IMPLEMENTATION,\n                importance=0.5 + (i % 50) / 100  # Varying importance\n            )\nE           AttributeError: 'async_generator' object has no attribute 'store_memory'\n\ntests/unit/test_gpt5_p4_memory.py:560: AttributeError\n___________________ TestMemoryNode.test_memory_node_creation ___________________\n\nself = <test_gpt5_p4_memory.TestMemoryNode object at 0x134d329a0>\n\n    def test_memory_node_creation(self):\n        \"\"\"Test memory node creation and initialization\"\"\"\n        node = MemoryNode(\n            content=\"Test memory content\",\n>           memory_type=MemoryType.IMPLEMENTATION,\n            importance=0.8,\n            tier=MemoryTier.WORKING\n        )\n\ntests/unit/test_gpt5_p4_memory.py:601: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ncls = <enum 'MemoryType'>, name = 'IMPLEMENTATION'\n\n    def __getattr__(cls, name):\n        \"\"\"\n        Return the enum member matching `name`\n    \n        We use __getattr__ instead of descriptors or inserting into the enum\n        class' __dict__ in order to support `name` and `value` being both\n        properties for enum members (which live in the class' __dict__) and\n        enum members themselves.\n        \"\"\"\n        if _is_dunder(name):\n            raise AttributeError(name)\n        try:\n            return cls._member_map_[name]\n        except KeyError:\n>           raise AttributeError(name) from None\nE           AttributeError: IMPLEMENTATION\n\n/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/enum.py:429: AttributeError\n________________ TestMemoryNode.test_memory_node_serialization _________________\n\nself = <test_gpt5_p4_memory.TestMemoryNode object at 0x134d32580>\n\n    def test_memory_node_serialization(self):\n        \"\"\"Test memory node to/from dictionary conversion\"\"\"\n        node = MemoryNode(\n            content=\"Serialization test\",\n>           memory_type=MemoryType.DECISION,\n            importance=0.7,\n            tier=MemoryTier.SHORT_TERM\n        )\n\ntests/unit/test_gpt5_p4_memory.py:619: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ncls = <enum 'MemoryType'>, name = 'DECISION'\n\n    def __getattr__(cls, name):\n        \"\"\"\n        Return the enum member matching `name`\n    \n        We use __getattr__ instead of descriptors or inserting into the enum\n        class' __dict__ in order to support `name` and `value` being both\n        properties for enum members (which live in the class' __dict__) and\n        enum members themselves.\n        \"\"\"\n        if _is_dunder(name):\n            raise AttributeError(name)\n        try:\n            return cls._member_map_[name]\n        except KeyError:\n>           raise AttributeError(name) from None\nE           AttributeError: DECISION\n\n/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/enum.py:429: AttributeError\n________________ TestMemoryNode.test_memory_node_update_access _________________\n\nself = <test_gpt5_p4_memory.TestMemoryNode object at 0x134ceb460>\n\n    def test_memory_node_update_access(self):\n        \"\"\"Test memory node access tracking\"\"\"\n        node = MemoryNode(\n            content=\"Access tracking test\",\n>           memory_type=MemoryType.USER_REQUEST,\n            importance=0.6\n        )\n\ntests/unit/test_gpt5_p4_memory.py:645: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ncls = <enum 'MemoryType'>, name = 'USER_REQUEST'\n\n    def __getattr__(cls, name):\n        \"\"\"\n        Return the enum member matching `name`\n    \n        We use __getattr__ instead of descriptors or inserting into the enum\n        class' __dict__ in order to support `name` and `value` being both\n        properties for enum members (which live in the class' __dict__) and\n        enum members themselves.\n        \"\"\"\n        if _is_dunder(name):\n            raise AttributeError(name)\n        try:\n            return cls._member_map_[name]\n        except KeyError:\n>           raise AttributeError(name) from None\nE           AttributeError: USER_REQUEST\n\n/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/enum.py:429: AttributeError\n_______________ TestMemoryNode.test_memory_node_importance_decay _______________\n\nself = <test_gpt5_p4_memory.TestMemoryNode object at 0x134d17dc0>\n\n    def test_memory_node_importance_decay(self):\n        \"\"\"Test memory importance decay over time\"\"\"\n        node = MemoryNode(\n            content=\"Importance decay test\",\n>           memory_type=MemoryType.OPTIMIZATION,\n            importance=0.9\n        )\n\ntests/unit/test_gpt5_p4_memory.py:662: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ncls = <enum 'MemoryType'>, name = 'OPTIMIZATION'\n\n    def __getattr__(cls, name):\n        \"\"\"\n        Return the enum member matching `name`\n    \n        We use __getattr__ instead of descriptors or inserting into the enum\n        class' __dict__ in order to support `name` and `value` being both\n        properties for enum members (which live in the class' __dict__) and\n        enum members themselves.\n        \"\"\"\n        if _is_dunder(name):\n            raise AttributeError(name)\n        try:\n            return cls._member_map_[name]\n        except KeyError:\n>           raise AttributeError(name) from None\nE           AttributeError: OPTIMIZATION\n\n/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/enum.py:429: AttributeError\n__________________ TestMemoryTierEnums.test_memory_type_enum ___________________\n\nself = <test_gpt5_p4_memory.TestMemoryTierEnums object at 0x134d42700>\n\n    def test_memory_type_enum(self):\n        \"\"\"Test memory type enumeration values\"\"\"\n        expected_types = [\n            \"user_request\",\n            \"implementation\",\n            \"decision\",\n            \"bug_fix\",\n            \"optimization\",\n            \"improvement\",\n            \"error\",\n            \"success\"\n        ]\n    \n        for memory_type in MemoryType:\n>           assert memory_type.value in expected_types\nE           AssertionError: assert 'episodic' in ['user_request', 'implementation', 'decision', 'bug_fix', 'optimization', 'improvement', ...]\nE            +  where 'episodic' = <MemoryType.EPISODIC: 'episodic'>.value\n\ntests/unit/test_gpt5_p4_memory.py:701: AssertionError\n__________ TestSecurityComplianceScanner.test_scanner_initialization ___________\n\nself = <test_gpt5_p5_security.TestSecurityComplianceScanner object at 0x134dec730>\n\n    @pytest.mark.asyncio\n    async def test_scanner_initialization(self):\n        \"\"\"Test security scanner initialization\"\"\"\n        scanner = SecurityComplianceScanner()\n>       await scanner.initialize()\nE       AttributeError: 'SecurityComplianceScanner' object has no attribute 'initialize'\n\ntests/unit/test_gpt5_p5_security.py:41: AttributeError\n__________ TestSecurityComplianceScanner.test_sql_injection_detection __________\n\nself = <test_gpt5_p5_security.TestSecurityComplianceScanner object at 0x134dec2b0>\nsecurity_scanner = <async_generator object TestSecurityComplianceScanner.security_scanner at 0x1352781f0>\n\n    @pytest.mark.asyncio\n    async def test_sql_injection_detection(self, security_scanner):\n        \"\"\"Test SQL injection vulnerability detection\"\"\"\n        vulnerable_code_samples = [\n            'query = f\"SELECT * FROM users WHERE id = {user_id}\"',\n            'cursor.execute(\"SELECT * FROM products WHERE name = \\'%s\\'\" % product_name)',\n            'sql = \"DELETE FROM logs WHERE date < \" + cutoff_date',\n            'db.raw(\"INSERT INTO table VALUES (\" + values + \")\")'\n        ]\n    \n        safe_code_samples = [\n            'query = \"SELECT * FROM users WHERE id = ?\"',\n            'cursor.execute(\"SELECT * FROM products WHERE name = ?\", (product_name,))',\n            'sql = \"DELETE FROM logs WHERE date < %s\"',\n            'db.query(\"INSERT INTO table VALUES (?)\", (values,))'\n        ]\n    \n        # Test vulnerable code detection\n        for code in vulnerable_code_samples:\n>           issues = await security_scanner.scan_code_snippet(code)\nE           AttributeError: 'async_generator' object has no attribute 'scan_code_snippet'\n\ntests/unit/test_gpt5_p5_security.py:75: AttributeError\n________ TestSecurityComplianceScanner.test_xss_vulnerability_detection ________\n\nself = <test_gpt5_p5_security.TestSecurityComplianceScanner object at 0x134dec220>\nsecurity_scanner = <async_generator object TestSecurityComplianceScanner.security_scanner at 0x135278550>\n\n    @pytest.mark.asyncio\n    async def test_xss_vulnerability_detection(self, security_scanner):\n        \"\"\"Test XSS vulnerability detection\"\"\"\n        vulnerable_code_samples = [\n            'return f\"<div>{user_input}</div>\"',\n            'html = \"<p>\" + request.form[\"comment\"] + \"</p>\"',\n            'content = f\"<script>var data = {json_data};</script>\"',\n            'template = \"<h1>\" + title + \"</h1>\"'\n        ]\n    \n        safe_code_samples = [\n            'return f\"<div>{escape(user_input)}</div>\"',\n            'html = \"<p>\" + html.escape(request.form[\"comment\"]) + \"</p>\"',\n            'content = f\"<script>var data = {json.dumps(json_data)};</script>\"',\n            'template = template.render(title=title)'\n        ]\n    \n        # Test vulnerable code detection\n        for code in vulnerable_code_samples:\n>           issues = await security_scanner.scan_code_snippet(code)\nE           AttributeError: 'async_generator' object has no attribute 'scan_code_snippet'\n\ntests/unit/test_gpt5_p5_security.py:110: AttributeError\n________ TestSecurityComplianceScanner.test_hardcoded_secrets_detection ________\n\nself = <test_gpt5_p5_security.TestSecurityComplianceScanner object at 0x134decb20>\nsecurity_scanner = <async_generator object TestSecurityComplianceScanner.security_scanner at 0x134fd94c0>\n\n    @pytest.mark.asyncio\n    async def test_hardcoded_secrets_detection(self, security_scanner):\n        \"\"\"Test hardcoded secrets detection\"\"\"\n        vulnerable_code_samples = [\n            'API_KEY = \"sk-1234567890abcdef\"',\n            'password = \"admin123\"',\n            'token = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9\"',\n            'aws_secret = \"AKIAIOSFODNN7EXAMPLE\"',\n            'database_url = \"postgres://user:password@localhost/db\"'\n        ]\n    \n        safe_code_samples = [\n            'API_KEY = os.environ.get(\"API_KEY\")',\n            'password = config.get(\"password\")',\n            'token = request.headers.get(\"Authorization\")',\n            'aws_secret = secrets.get_secret_value(\"aws_secret\")',\n            'database_url = settings.DATABASE_URL'\n        ]\n    \n        # Test vulnerable code detection\n        for code in vulnerable_code_samples:\n>           issues = await security_scanner.scan_code_snippet(code)\nE           AttributeError: 'async_generator' object has no attribute 'scan_code_snippet'\n\ntests/unit/test_gpt5_p5_security.py:147: AttributeError\n_________ TestSecurityComplianceScanner.test_insecure_crypto_detection _________\n\nself = <test_gpt5_p5_security.TestSecurityComplianceScanner object at 0x134decb80>\nsecurity_scanner = <async_generator object TestSecurityComplianceScanner.security_scanner at 0x135278ca0>\n\n    @pytest.mark.asyncio\n    async def test_insecure_crypto_detection(self, security_scanner):\n        \"\"\"Test insecure cryptography detection\"\"\"\n        vulnerable_code_samples = [\n            'from Crypto.Cipher import DES',\n            'hashlib.md5(password)',\n            'random.random()',\n            'ssl_context.check_hostname = False',\n            'hashlib.sha1(data)'\n        ]\n    \n        safe_code_samples = [\n            'from Crypto.Cipher import AES',\n            'hashlib.sha256(password)',\n            'secrets.SystemRandom()',\n            'ssl.create_default_context()',\n            'hashlib.sha256(data)'\n        ]\n    \n        # Test vulnerable code detection\n        for code in vulnerable_code_samples:\n>           issues = await security_scanner.scan_code_snippet(code)\nE           AttributeError: 'async_generator' object has no attribute 'scan_code_snippet'\n\ntests/unit/test_gpt5_p5_security.py:184: AttributeError\n_________ TestSecurityComplianceScanner.test_path_traversal_detection __________\n\nself = <test_gpt5_p5_security.TestSecurityComplianceScanner object at 0x134decdf0>\nsecurity_scanner = <async_generator object TestSecurityComplianceScanner.security_scanner at 0x1352a41f0>\n\n    @pytest.mark.asyncio\n    async def test_path_traversal_detection(self, security_scanner):\n        \"\"\"Test path traversal vulnerability detection\"\"\"\n        vulnerable_code_samples = [\n            'open(user_filename, \"r\")',\n            'file_path = f\"/uploads/{request.form[\\\"filename\\\"]}\"',\n            'with open(f\"./files/{filename}\") as f:',\n            'os.path.join(\"/base\", user_input)'\n        ]\n    \n        safe_code_samples = [\n            'open(secure_filename(user_filename), \"r\")',\n            'file_path = safe_join(\"/uploads\", request.form[\"filename\"])',\n            'with open(validate_path(f\"./files/{filename}\")) as f:',\n            'os.path.join(\"/base\", os.path.basename(user_input))'\n        ]\n    \n        # Test vulnerable code detection\n        for code in vulnerable_code_samples:\n>           issues = await security_scanner.scan_code_snippet(code)\nE           AttributeError: 'async_generator' object has no attribute 'scan_code_snippet'\n\ntests/unit/test_gpt5_p5_security.py:220: AttributeError\n_________________ TestSecurityComplianceScanner.test_scan_file _________________\n\nself = <test_gpt5_p5_security.TestSecurityComplianceScanner object at 0x134dd6c70>\nsecurity_scanner = <async_generator object TestSecurityComplianceScanner.security_scanner at 0x134fd9f70>\ntmp_path = PosixPath('/private/var/folders/gc/cjnggvbd1bdgsblrng_h4mf40000gn/T/pytest-of-apple/pytest-0/test_scan_file0')\n\n        @pytest.mark.asyncio\n        async def test_scan_file(self, security_scanner, tmp_path):\n            \"\"\"Test scanning individual files\"\"\"\n            # Create test file with vulnerabilities\n            test_file = tmp_path / \"vulnerable_test.py\"\n            test_file.write_text('''\n    import hashlib\n    import os\n    \n    # Hardcoded secret\n    API_KEY = \"sk-1234567890abcdef\"\n    \n    def get_user(user_id):\n        # SQL injection vulnerability\n        query = f\"SELECT * FROM users WHERE id = {user_id}\"\n        return execute_query(query)\n    \n    def render_comment(comment):\n        # XSS vulnerability\n        return f\"<div>{comment}</div>\"\n    \n    def hash_password(password):\n        # Weak crypto\n        return hashlib.md5(password.encode()).hexdigest()\n    ''')\n    \n            # Scan the file\n>           scan_result = await security_scanner.scan_file(str(test_file))\nE           AttributeError: 'async_generator' object has no attribute 'scan_file'\n\ntests/unit/test_gpt5_p5_security.py:263: AttributeError\n______________ TestSecurityComplianceScanner.test_scan_directory _______________\n\nself = <test_gpt5_p5_security.TestSecurityComplianceScanner object at 0x134dd6160>\nsecurity_scanner = <async_generator object TestSecurityComplianceScanner.security_scanner at 0x135264c10>\ntmp_path = PosixPath('/private/var/folders/gc/cjnggvbd1bdgsblrng_h4mf40000gn/T/pytest-of-apple/pytest-0/test_scan_directory0')\n\n        @pytest.mark.asyncio\n        async def test_scan_directory(self, security_scanner, tmp_path):\n            \"\"\"Test scanning entire directories\"\"\"\n            # Create test files\n            files_data = {\n                \"app.py\": '''\n    API_KEY = \"secret123\"\n    def sql_query(id):\n        return f\"SELECT * FROM table WHERE id = {id}\"\n    ''',\n                \"utils.py\": '''\n    import hashlib\n    def weak_hash(data):\n        return hashlib.md5(data).hexdigest()\n    ''',\n                \"views.py\": '''\n    def render_user_input(data):\n        return f\"<p>{data}</p>\"\n    '''\n            }\n    \n            # Write test files\n            for filename, content in files_data.items():\n                (tmp_path / filename).write_text(content)\n    \n            # Scan directory\n>           scan_results = await security_scanner.scan_directory(str(tmp_path))\nE           AttributeError: 'async_generator' object has no attribute 'scan_directory'\n\ntests/unit/test_gpt5_p5_security.py:301: AttributeError\n__________ TestSecurityComplianceScanner.test_owasp_compliance_check ___________\n\nself = <test_gpt5_p5_security.TestSecurityComplianceScanner object at 0x134dd62b0>\nsecurity_scanner = <async_generator object TestSecurityComplianceScanner.security_scanner at 0x135278af0>\n\n    @pytest.mark.asyncio\n    async def test_owasp_compliance_check(self, security_scanner):\n        \"\"\"Test OWASP compliance framework validation\"\"\"\n        # Create scan results with various vulnerabilities\n        issues = [\n>           SecurityVulnerability(\n                vulnerability_type=VulnerabilityType.SQL_INJECTION,\n                severity=SecurityLevel.HIGH,\n                description=\"SQL injection vulnerability\",\n                line_number=10\n            ),\n            SecurityVulnerability(\n                vulnerability_type=VulnerabilityType.XSS,\n                severity=SecurityLevel.MEDIUM,\n                description=\"XSS vulnerability\",\n                line_number=15\n            ),\n            SecurityVulnerability(\n                vulnerability_type=VulnerabilityType.HARDCODED_SECRETS,\n                severity=SecurityLevel.CRITICAL,\n                description=\"Hardcoded API key\",\n                line_number=5\n            )\n        ]\nE       TypeError: __init__() got an unexpected keyword argument 'vulnerability_type'\n\ntests/unit/test_gpt5_p5_security.py:314: TypeError\n___________ TestSecurityComplianceScanner.test_gdpr_compliance_check ___________\n\nself = <test_gpt5_p5_security.TestSecurityComplianceScanner object at 0x134dd64f0>\nsecurity_scanner = <async_generator object TestSecurityComplianceScanner.security_scanner at 0x135264700>\n\n    @pytest.mark.asyncio\n    async def test_gdpr_compliance_check(self, security_scanner):\n        \"\"\"Test GDPR compliance framework validation\"\"\"\n        # Create code with potential GDPR issues\n        code_samples = [\n            'user_data = {\"email\": email, \"name\": name, \"ip\": request.remote_addr}',\n            'log.info(f\"User {user.email} performed action\")',\n            'analytics.track(user_id, sensitive_data)',\n            'cookie_data = request.cookies.get(\"tracking\")'\n        ]\n    \n        all_issues = []\n        for code in code_samples:\n>           issues = await security_scanner.scan_code_snippet(code)\nE           AttributeError: 'async_generator' object has no attribute 'scan_code_snippet'\n\ntests/unit/test_gpt5_p5_security.py:368: AttributeError\n_________ TestSecurityComplianceScanner.test_pci_dss_compliance_check __________\n\nself = <test_gpt5_p5_security.TestSecurityComplianceScanner object at 0x134decca0>\nsecurity_scanner = <async_generator object TestSecurityComplianceScanner.security_scanner at 0x135278310>\n\n    @pytest.mark.asyncio\n    async def test_pci_dss_compliance_check(self, security_scanner):\n        \"\"\"Test PCI-DSS compliance framework validation\"\"\"\n        # Create issues related to payment card data\n        issues = [\n>           SecurityVulnerability(\n                vulnerability_type=VulnerabilityType.HARDCODED_SECRETS,\n                severity=SecurityLevel.CRITICAL,\n                description=\"Hardcoded payment API key\",\n                line_number=5,\n                context=\"payment_api_key = 'pk_test_123456'\"\n            ),\n            SecurityVulnerability(\n                vulnerability_type=VulnerabilityType.INSECURE_CRYPTO,\n                severity=SecurityLevel.HIGH,\n                description=\"Weak encryption for payment data\",\n                line_number=20,\n                context=\"hashlib.md5(credit_card_number)\"\n            )\n        ]\nE       TypeError: __init__() got an unexpected keyword argument 'vulnerability_type'\n\ntests/unit/test_gpt5_p5_security.py:393: TypeError\n______________ TestSecurityComplianceScanner.test_risk_assessment ______________\n\nself = <test_gpt5_p5_security.TestSecurityComplianceScanner object at 0x134dec5b0>\nsecurity_scanner = <async_generator object TestSecurityComplianceScanner.security_scanner at 0x1351c7ca0>\n\n    @pytest.mark.asyncio\n    async def test_risk_assessment(self, security_scanner):\n        \"\"\"Test security risk assessment calculation\"\"\"\n        # Create issues with different severity levels\n        issues = [\n>           SecurityVulnerability(\n                vulnerability_type=VulnerabilityType.HARDCODED_SECRETS,\n                severity=SecurityLevel.CRITICAL,\n                description=\"Critical secret exposure\"\n            ),\n            SecurityVulnerability(\n                vulnerability_type=VulnerabilityType.SQL_INJECTION,\n                severity=SecurityLevel.HIGH,\n                description=\"SQL injection risk\"\n            ),\n            SecurityVulnerability(\n                vulnerability_type=VulnerabilityType.XSS,\n                severity=SecurityLevel.MEDIUM,\n                description=\"XSS vulnerability\"\n            ),\n            SecurityVulnerability(\n                vulnerability_type=VulnerabilityType.WEAK_RANDOM,\n                severity=SecurityLevel.LOW,\n                description=\"Weak random number generation\"\n            )\n        ]\nE       TypeError: __init__() got an unexpected keyword argument 'vulnerability_type'\n\ntests/unit/test_gpt5_p5_security.py:430: TypeError\n________ TestSecurityComplianceScanner.test_security_report_generation _________\n\nself = <test_gpt5_p5_security.TestSecurityComplianceScanner object at 0x134decc10>\nsecurity_scanner = <async_generator object TestSecurityComplianceScanner.security_scanner at 0x135278820>\ntmp_path = PosixPath('/private/var/folders/gc/cjnggvbd1bdgsblrng_h4mf40000gn/T/pytest-of-apple/pytest-0/test_security_report_generatio0')\n\n    @pytest.mark.asyncio\n    async def test_security_report_generation(self, security_scanner, tmp_path):\n        \"\"\"Test comprehensive security report generation\"\"\"\n        # Create multiple scan results\n        scan_results = [\n            SecurityScanResult(\n                file_path=\"/app/main.py\",\n                issues=[\n>                   SecurityVulnerability(\n                        vulnerability_type=VulnerabilityType.SQL_INJECTION,\n                        severity=SecurityLevel.HIGH,\n                        description=\"SQL injection in user query\"\n                    )\n                ],\n                scan_timestamp=1234567890\n            ),\n            SecurityScanResult(\n                file_path=\"/app/utils.py\",\n                issues=[\n                    SecurityVulnerability(\n                        vulnerability_type=VulnerabilityType.HARDCODED_SECRETS,\n                        severity=SecurityLevel.CRITICAL,\n                        description=\"API key hardcoded\"\n                    )\n                ],\n                scan_timestamp=1234567890\n            )\n        ]\nE       TypeError: __init__() got an unexpected keyword argument 'vulnerability_type'\n\ntests/unit/test_gpt5_p5_security.py:476: TypeError\n__________ TestSecurityComplianceScanner.test_false_positive_handling __________\n\nself = <test_gpt5_p5_security.TestSecurityComplianceScanner object at 0x134dd6070>\nsecurity_scanner = <async_generator object TestSecurityComplianceScanner.security_scanner at 0x1352788b0>\n\n    @pytest.mark.asyncio\n    async def test_false_positive_handling(self, security_scanner):\n        \"\"\"Test handling of false positives in security scanning\"\"\"\n        # Code that might trigger false positives\n        code_samples = [\n            '# This is not a real API key: \"sk-test-example\"',\n            'test_query = \"SELECT * FROM test_table WHERE id = 1\"',  # Static query\n            'example_html = \"<div>Safe static content</div>\"',\n            'hash_comment = \"Use SHA256 instead of MD5 for production\"'\n        ]\n    \n        total_false_positives = 0\n    \n        for code in code_samples:\n>           issues = await security_scanner.scan_code_snippet(code)\nE           AttributeError: 'async_generator' object has no attribute 'scan_code_snippet'\n\ntests/unit/test_gpt5_p5_security.py:536: AttributeError\n_______ TestSecurityComplianceScanner.test_vulnerability_pattern_updates _______\n\nself = <test_gpt5_p5_security.TestSecurityComplianceScanner object at 0x134dd6910>\nsecurity_scanner = <async_generator object TestSecurityComplianceScanner.security_scanner at 0x134fe9310>\n\n    @pytest.mark.asyncio\n    async def test_vulnerability_pattern_updates(self, security_scanner):\n        \"\"\"Test dynamic vulnerability pattern updates\"\"\"\n        # Add new custom vulnerability pattern\n        custom_pattern = {\n            \"name\": \"Custom API Exposure\",\n            \"pattern\": r\"app\\.run\\(host=['\\\"]0\\.0\\.0\\.0['\\\"]\",\n            \"description\": \"Flask app exposed to all interfaces\",\n            \"severity\": SecurityLevel.MEDIUM\n        }\n    \n        # Add pattern to scanner\n>       await security_scanner.add_vulnerability_pattern(\n            VulnerabilityType.INFORMATION_DISCLOSURE,\n            custom_pattern\n        )\nE       AttributeError: 'async_generator' object has no attribute 'add_vulnerability_pattern'\n\ntests/unit/test_gpt5_p5_security.py:559: AttributeError\n_____________ TestSecurityComplianceScanner.test_scan_performance ______________\n\nself = <test_gpt5_p5_security.TestSecurityComplianceScanner object at 0x134dd6cd0>\nsecurity_scanner = <async_generator object TestSecurityComplianceScanner.security_scanner at 0x134fe9670>\ntmp_path = PosixPath('/private/var/folders/gc/cjnggvbd1bdgsblrng_h4mf40000gn/T/pytest-of-apple/pytest-0/test_scan_performance0')\n\n        @pytest.mark.asyncio\n        async def test_scan_performance(self, security_scanner, tmp_path):\n            \"\"\"Test scanning performance with larger codebase\"\"\"\n            import time\n    \n            # Create multiple files with various vulnerabilities\n            num_files = 20\n            for i in range(num_files):\n                test_file = tmp_path / f\"test_file_{i}.py\"\n                test_file.write_text(f'''\n    # File {i}\n    api_key = \"sk-test-{i}\"\n    def query_{i}(user_id):\n        return f\"SELECT * FROM table_{i} WHERE id = {{user_id}}\"\n    \n    def render_{i}(data):\n        return f\"<div>{{data}}</div>\"\n    ''')\n    \n            # Measure scan performance\n            start_time = time.time()\n>           scan_results = await security_scanner.scan_directory(str(tmp_path))\nE           AttributeError: 'async_generator' object has no attribute 'scan_directory'\n\ntests/unit/test_gpt5_p5_security.py:596: AttributeError\n____________ TestSecurityComplianceScanner.test_concurrent_scanning ____________\n\nself = <test_gpt5_p5_security.TestSecurityComplianceScanner object at 0x134d481f0>\nsecurity_scanner = <async_generator object TestSecurityComplianceScanner.security_scanner at 0x134fe9a60>\ntmp_path = PosixPath('/private/var/folders/gc/cjnggvbd1bdgsblrng_h4mf40000gn/T/pytest-of-apple/pytest-0/test_concurrent_scanning0')\n\n        @pytest.mark.asyncio\n        async def test_concurrent_scanning(self, security_scanner, tmp_path):\n            \"\"\"Test concurrent file scanning\"\"\"\n            # Create test files\n            test_files = []\n            for i in range(5):\n                test_file = tmp_path / f\"concurrent_test_{i}.py\"\n                test_file.write_text(f'''\n    secret_{i} = \"hardcoded_secret_{i}\"\n    def vulnerable_query_{i}(id):\n        return f\"SELECT * FROM table WHERE id = {{id}}\"\n    ''')\n                test_files.append(str(test_file))\n    \n            # Scan files concurrently\n>           scan_tasks = [security_scanner.scan_file(file_path) for file_path in test_files]\n\ntests/unit/test_gpt5_p5_security.py:622: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n.0 = <list_iterator object at 0x1350625e0>\n\n>   scan_tasks = [security_scanner.scan_file(file_path) for file_path in test_files]\nE   AttributeError: 'async_generator' object has no attribute 'scan_file'\n\ntests/unit/test_gpt5_p5_security.py:622: AttributeError\n____________ TestSecurityVulnerability.test_security_issue_creation ____________\n\nself = <test_gpt5_p5_security.TestSecurityVulnerability object at 0x134d48d30>\n\n    def test_security_issue_creation(self):\n        \"\"\"Test security issue creation and properties\"\"\"\n>       issue = SecurityVulnerability(\n            vulnerability_type=VulnerabilityType.SQL_INJECTION,\n            severity=SecurityLevel.HIGH,\n            description=\"SQL injection detected\",\n            line_number=42,\n            context=\"query = f'SELECT * FROM users WHERE id = {user_id}'\"\n        )\nE       TypeError: __init__() got an unexpected keyword argument 'vulnerability_type'\n\ntests/unit/test_gpt5_p5_security.py:639: TypeError\n_________ TestSecurityVulnerability.test_security_issue_serialization __________\n\nself = <test_gpt5_p5_security.TestSecurityVulnerability object at 0x134d48280>\n\n    def test_security_issue_serialization(self):\n        \"\"\"Test security issue serialization\"\"\"\n>       issue = SecurityVulnerability(\n            vulnerability_type=VulnerabilityType.XSS,\n            severity=SecurityLevel.MEDIUM,\n            description=\"XSS vulnerability\"\n        )\nE       TypeError: __init__() got an unexpected keyword argument 'vulnerability_type'\n\ntests/unit/test_gpt5_p5_security.py:655: TypeError\n_________________ TestSecurityLevelEnum.test_risk_level_values _________________\n\nself = <test_gpt5_p5_security.TestSecurityLevelEnum object at 0x134d48460>\n\n    def test_risk_level_values(self):\n        \"\"\"Test risk level enumeration values\"\"\"\n>       assert SecurityLevel.CRITICAL.value == \"critical\"\nE       AssertionError: assert 'CRITICAL' == 'critical'\nE         \nE         - critical\nE         + CRITICAL\n\ntests/unit/test_gpt5_p5_security.py:685: AssertionError\n___________ TestVulnerabilityTypeEnum.test_vulnerability_types_exist ___________\n\nself = <test_gpt5_p5_security.TestVulnerabilityTypeEnum object at 0x134d55a90>\n\n    def test_vulnerability_types_exist(self):\n        \"\"\"Test that all expected vulnerability types exist\"\"\"\n        expected_types = [\n            VulnerabilityType.SQL_INJECTION,\n            VulnerabilityType.XSS,\n            VulnerabilityType.HARDCODED_SECRETS,\n            VulnerabilityType.INSECURE_CRYPTO,\n            VulnerabilityType.PATH_TRAVERSAL,\n>           VulnerabilityType.WEAK_RANDOM,\n            VulnerabilityType.INFORMATION_DISCLOSURE\n        ]\n\ntests/unit/test_gpt5_p5_security.py:714: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ncls = <enum 'VulnerabilityType'>, name = 'WEAK_RANDOM'\n\n    def __getattr__(cls, name):\n        \"\"\"\n        Return the enum member matching `name`\n    \n        We use __getattr__ instead of descriptors or inserting into the enum\n        class' __dict__ in order to support `name` and `value` being both\n        properties for enum members (which live in the class' __dict__) and\n        enum members themselves.\n        \"\"\"\n        if _is_dunder(name):\n            raise AttributeError(name)\n        try:\n            return cls._member_map_[name]\n        except KeyError:\n>           raise AttributeError(name) from None\nE           AttributeError: WEAK_RANDOM\n\n/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/enum.py:429: AttributeError\n___________ TestVulnerabilityTypeEnum.test_vulnerability_type_values ___________\n\nself = <test_gpt5_p5_security.TestVulnerabilityTypeEnum object at 0x134d55c70>\n\n    def test_vulnerability_type_values(self):\n        \"\"\"Test vulnerability type string values\"\"\"\n>       assert VulnerabilityType.SQL_INJECTION.value == \"sql_injection\"\nE       AssertionError: assert 1 == 'sql_injection'\nE        +  where 1 = <VulnerabilityType.SQL_INJECTION: 1>.value\nE        +    where <VulnerabilityType.SQL_INJECTION: 1> = VulnerabilityType.SQL_INJECTION\n\ntests/unit/test_gpt5_p5_security.py:723: AssertionError\n_______ TestSelfHealingOrchestrator.test_repair_action_execution_failure _______\n\nself = <test_gpt5_p6_healing.TestSelfHealingOrchestrator object at 0x134d6eaf0>\nhealing_orchestrator = <test_gpt5_p6_healing.MockSelfHealingOrchestrator object at 0x134e57730>\nsample_repair_actions = [RepairAction(action_id='restart_service', name='Restart Application Service', description='Restart the main applicati...nent='cache_layer', repair_script='redis-cli FLUSHDB', estimated_duration=10, success_rate=0.99, rollback_script=None)]\n\n    @pytest.mark.asyncio\n    async def test_repair_action_execution_failure(self, healing_orchestrator, sample_repair_actions):\n        \"\"\"Test failed repair action execution\"\"\"\n        action = sample_repair_actions[0]  # restart_service action\n    \n        # Mock failed execution\n        with patch('random.random', return_value=0.99):  # Success rate is 0.95, so this should fail\n            result = await healing_orchestrator.execute_repair_action(action)\n    \n>       assert result['success'] is False\nE       assert True is False\n\ntests/unit/test_gpt5_p6_healing.py:672: AssertionError\n______ TestSelfHealingOrchestrator.test_repair_action_rollback_capability ______\n\nself = <test_gpt5_p6_healing.TestSelfHealingOrchestrator object at 0x134d87a30>\nhealing_orchestrator = <test_gpt5_p6_healing.MockSelfHealingOrchestrator object at 0x135241250>\n\n    @pytest.mark.asyncio\n    async def test_repair_action_rollback_capability(self, healing_orchestrator):\n        \"\"\"Test repair action rollback capability\"\"\"\n        action = RepairAction(\n            action_id=\"test_rollback\",\n            name=\"Test Rollback Action\",\n            description=\"Action with rollback capability\",\n            target_component=\"test_component\",\n            repair_script=\"echo 'repair'\",\n            estimated_duration=5,\n            success_rate=0.0,  # Force failure\n            rollback_script=\"echo 'rollback'\"\n        )\n    \n        # Execute failing repair\n        with patch('random.random', return_value=0.99):\n            result = await healing_orchestrator.execute_repair_action(action)\n    \n>       assert result['success'] is False\nE       assert True is False\n\ntests/unit/test_gpt5_p6_healing.py:802: AssertionError\n___ TestSystemResilienceValidation.test_chaos_engineering_network_partition ____\n\nself = <test_gpt5_p6_healing.TestSystemResilienceValidation object at 0x134f75940>\nhealing_orchestrator = <test_gpt5_p6_healing.MockSelfHealingOrchestrator object at 0x1351b4bb0>\n\n    @pytest.mark.asyncio\n    async def test_chaos_engineering_network_partition(self, healing_orchestrator):\n        \"\"\"Test system behavior during network partition\"\"\"\n        # Simulate network partition scenario\n        network_partition_metrics = SystemMetrics(\n            cpu_usage=50.0,\n            memory_usage=60.0,\n            disk_usage=40.0,\n            response_time=10.0,  # Very slow due to network issues\n            error_rate=0.3,      # High error rate\n            active_connections=0  # No connections due to partition\n        )\n    \n        anomalies = await healing_orchestrator.detect_anomalies(network_partition_metrics)\n    \n        # Should detect network-related anomalies\n>       assert len(anomalies) >= 2  # At least response time and error rate issues\nE       AssertionError: assert 1 >= 2\nE        +  where 1 = len([{'description': 'Response time at 10.0s, exceeds threshold', 'severity': 'critical', 'threshold': 2.0, 'type': 'slow_response_time', ...}])\n\ntests/unit/test_gpt5_p6_healing.py:1047: AssertionError\n__________ TestKnowledgeGraphManager.test_entity_embedding_generation __________\n\nself = <test_gpt5_p7_knowledge.TestKnowledgeGraphManager object at 0x134d5b400>\nknowledge_graph = <test_gpt5_p7_knowledge.MockKnowledgeGraphManager object at 0x159d36b50>\nsample_entities = [KnowledgeEntity(entity_id='func_001', name='calculate_fibonacci', entity_type=<KnowledgeEntityType.FUNCTION: 'functio...etime(2025, 11, 29, 6, 5, 12, 183702), last_updated=datetime.datetime(2025, 11, 29, 6, 5, 12, 183702), embedding=None)]\n\n    @pytest.mark.asyncio\n    async def test_entity_embedding_generation(self, knowledge_graph, sample_entities):\n        \"\"\"Test automatic embedding generation for entities\"\"\"\n        await knowledge_graph.initialize()\n    \n        entity = sample_entities[0]\n        entity_id = await knowledge_graph.add_entity(entity)\n    \n        # Verify embedding was generated\n        stored_entity = await knowledge_graph.get_entity(entity_id)\n        assert stored_entity.embedding is not None\n>       assert len(stored_entity.embedding) == 128  # Mock embedding size\nE       AssertionError: assert 384 == 128\nE        +  where 384 = len([0.018738416954874992, 0.1349063366651535, -0.12806172668933868, -0.01602982170879841, -0.21783770620822906, -0.24590706825256348, ...])\nE        +    where [0.018738416954874992, 0.1349063366651535, -0.12806172668933868, -0.01602982170879841, -0.21783770620822906, -0.24590706825256348, ...] = KnowledgeEntity(entity_id='func_001', name='calculate_fibonacci', entity_type=<KnowledgeEntityType.FUNCTION: 'function'>, properties={'parameters': ['n'], 'return_type': 'int', 'complexity': 'medium', 'algorithm': 'recursive'}, source_file='utils/math.py', line_number=15, created_at=datetime.datetime(2025, 11, 29, 6, 5, 12, 183631), last_updated=datetime.datetime(2025, 11, 29, 6, 5, 12, 183631), embedding=[0.018738416954874992, 0.1349063366651535, -0.12806172668933868, -0.01602982170879841, -0.21783770620822906, -0.24590706825256348, -0.1323704719543457, 0.1900198608636856, -0.05490133538842201, 0.08478762954473495, -0.19921839237213135, -0.09158601611852646, -0.1801186352968216, 0.03880838677287102, -0.2407284379005432, 0.012072399258613586, -0.2985793650150299, -0.10020527988672256, 0.2812707722187042, -0.17621691524982452, 0.13667620718479156, 0.083079032599926, 0.025694333016872406, -0.1188061460852623, -0.03427993133664131, -0.07818584889173508, -0.11171764135360718, -0.01091688871383667, 0.039300188422203064, 0.07384054362773895, -0.02648409642279148, 0.059581656008958817, 0.2748962342739105, -0.01118431519716978, 0.007115548010915518, -0.012586942873895168, 0.0934748351573...8481445, -0.31211569905281067, -0.12102707475423813, -0.05159579589962959, 0.2619323134422302, 0.16276627779006958, -0.04772930219769478, -0.04592055082321167, -0.01135234534740448, -0.01940072886645794, -0.10998407751321793, -0.02672317624092102, 0.0400267131626606, 0.04254743829369545, -0.17569808661937714, 0.15368472039699554, -0.009143284521996975, -0.02603040635585785, -0.01069360226392746, -0.2554955780506134, -0.1066148653626442, 0.04944474622607231, 0.028236469253897667, 0.14857923984527588, 0.01981743611395359, -0.00027081556618213654, -0.36359140276908875, 0.18299441039562225, -0.044976383447647095, 0.1277623325586319, -0.1351509392261505, -0.04106520488858223, 0.045510660856962204, 0.28640446066856384, -0.08200975507497787, -0.09721241146326065, 0.032869551330804825, -0.1013127788901329, 0.11705547571182251, -0.00840100459754467, -0.19583408534526825, -0.03489509969949722, 0.06732281297445297, 0.15099196135997772, 0.00949768628925085, -0.23177580535411835, -0.12551267445087433, 0.12059986591339111, -0.016102615743875504, -0.016371555626392365, 0.07153160125017166, 0.13740891218185425, 0.02499288320541382, 0.06981119513511658, 0.09931892156600952, -0.006103192921727896]).embedding\n\ntests/unit/test_gpt5_p7_knowledge.py:1099: AssertionError\n______ TestKnowledgeGraphManager.test_multi_depth_relationship_traversal _______\n\nself = <test_gpt5_p7_knowledge.TestKnowledgeGraphManager object at 0x134f3c490>\nknowledge_graph = <test_gpt5_p7_knowledge.MockKnowledgeGraphManager object at 0x17fb53d60>\n\n    @pytest.mark.asyncio\n    async def test_multi_depth_relationship_traversal(self, knowledge_graph):\n        \"\"\"Test multi-depth relationship traversal\"\"\"\n        await knowledge_graph.initialize()\n    \n        # Create a chain of entities: A -> B -> C\n        entities = []\n        for i in range(3):\n            entity = KnowledgeEntity(\n                entity_id=f\"entity_{chr(65+i)}\",  # A, B, C\n                name=f\"Entity {chr(65+i)}\",\n                entity_type=KnowledgeEntityType.FUNCTION,\n                properties={}\n            )\n            entities.append(entity)\n            await knowledge_graph.add_entity(entity)\n    \n        # Create relationships: A depends on B, B depends on C\n        rel1 = KnowledgeRelationship(\n            relationship_id=\"rel_AB\",\n            source_entity_id=\"entity_A\",\n            target_entity_id=\"entity_B\",\n            relationship_type=RelationshipType.DEPENDS_ON,\n            properties={},\n            strength=0.8,\n            confidence=0.9\n        )\n        rel2 = KnowledgeRelationship(\n            relationship_id=\"rel_BC\",\n            source_entity_id=\"entity_B\",\n            target_entity_id=\"entity_C\",\n            relationship_type=RelationshipType.DEPENDS_ON,\n            properties={},\n            strength=0.8,\n            confidence=0.9\n        )\n    \n        await knowledge_graph.add_relationship(rel1)\n        await knowledge_graph.add_relationship(rel2)\n    \n        # Test depth 1 traversal from A\n        related_depth1 = await knowledge_graph.get_related_entities(\"entity_A\", max_depth=1)\n>       assert len(related_depth1) == 1  # Should find B only\nE       AssertionError: assert 2 == 1\nE        +  where 2 = len([(KnowledgeEntity(entity_id='entity_B', name='Entity B', entity_type=<KnowledgeEntityType.FUNCTION: 'function'>, properties={}, source_file=None, line_number=None, created_at=datetime.datetime(2025, 11, 29, 6, 8, 19, 684518), last_updated=datetime.datetime(2025, 11, 29, 6, 8, 19, 684518), embedding=[0.15357787907123566, 0.21851904690265656, -0.03356122970581055, -0.1754346787929535, -0.3802368640899658, 0.4468083083629608, 0.4676118791103363, -0.03751600533723831, 0.39635953307151794, 0.1938374936580658, 0.31582751870155334, -0.6148790717124939, 0.013694601133465767, -0.1496494859457016, 1.0637904405593872, 1.0203049182891846, -0.22522582113742828, -0.23878058791160583, -0.5903932452201843, -0.2659541666507721, 0.22548829019069672, 0.03651496767997742, -0.25278612971305847, -0.08225025236606598, -0.41254767775535583, -0.6875367164611816, 0.047052688896656036, -0.09145534038543701, 0.23322932422161102, -0.4079969823360443, -0.16807334125041962, 0.2648426294326782, -0.5033220052719116, 0.24928149580955505, 0.03023022785782814, 0.19184160232543945, 0.05291428789496422, 0.007936039008200169, 0.13013909757137299, 0.01863395795226097, -0.2559421956539154, -0.3510308563709259, 0.0710441...-0.3575142025947571, -0.046145785599946976, -0.13608220219612122, -0.21315349638462067, 0.28258806467056274, -0.0652909204363823, 0.1984614133834839, -0.03615951910614967, 0.5771116018295288, 0.07241171598434448, 0.2448239028453827, 0.7500684857368469, 0.5363514423370361, 0.5451506972312927, 0.05157880112528801, 0.18366959691047668, 0.6151615381240845, -0.03264067322015762, -0.23879767954349518, 0.28772810101509094, 0.49527913331985474, 0.13890045881271362, -0.5620983242988586, 0.2554973065853119, 0.363494336605072, -0.2071915566921234, 0.23452697694301605, 0.13468234241008759, 0.010979877784848213, -0.18453755974769592, -0.2687084972858429, 0.4302978515625, 0.06300585716962814, 0.11360186338424683, 0.15512524545192719, 0.12463541328907013, -0.3241696059703827, -0.24982404708862305, -0.3800990879535675, 0.5283379554748535, -0.5403686165809631, -0.09362417459487915, 0.32634326815605164, -0.2814692556858063]), KnowledgeRelationship(relationship_id='rel_BC', source_entity_id='entity_B', target_entity_id='entity_C', relationship_type=<RelationshipType.DEPENDS_ON: 'depends_on'>, properties={}, strength=0.8, confidence=0.9, created_at=datetime.datetime(2025, 11, 29, 6, 8, 27, 660539)))])\n\ntests/unit/test_gpt5_p7_knowledge.py:1440: AssertionError\n_________ TestKnowledgeGraphManager.test_large_scale_graph_performance _________\n\nself = <test_gpt5_p7_knowledge.TestKnowledgeGraphManager object at 0x134d96ac0>\nknowledge_graph = <test_gpt5_p7_knowledge.MockKnowledgeGraphManager object at 0x17fc92ca0>\n\n    @pytest.mark.asyncio\n    async def test_large_scale_graph_performance(self, knowledge_graph):\n        \"\"\"Test performance with larger scale knowledge graph\"\"\"\n        await knowledge_graph.initialize()\n    \n        # Add many entities\n        entity_count = 100\n        start_time = asyncio.get_event_loop().time()\n    \n        for i in range(entity_count):\n            entity = KnowledgeEntity(\n                entity_id=f\"perf_entity_{i:04d}\",\n                name=f\"PerformanceEntity{i}\",\n                entity_type=KnowledgeEntityType.FUNCTION if i % 2 == 0 else KnowledgeEntityType.CLASS,\n                properties={\"index\": i, \"group\": i // 10}\n            )\n            await knowledge_graph.add_entity(entity)\n    \n        entity_creation_time = asyncio.get_event_loop().time() - start_time\n    \n        # Test search performance\n        search_start = asyncio.get_event_loop().time()\n        results = await knowledge_graph.semantic_search(\"PerformanceEntity50\", top_k=10)\n        search_time = asyncio.get_event_loop().time() - search_start\n    \n        # Verify results\n        assert len(knowledge_graph.entities) == entity_count\n        assert len(results) > 0\n    \n        # Performance assertions (adjust thresholds as needed)\n>       assert entity_creation_time < 5.0  # Should create 100 entities in under 5 seconds\nE       assert 417.954783865 < 5.0\n\ntests/unit/test_gpt5_p7_knowledge.py:1499: AssertionError\n___ TestKnowledgeTransferAndLearning.test_cross_project_pattern_recognition ____\n\nself = <test_gpt5_p7_knowledge.TestKnowledgeTransferAndLearning object at 0x134f3c910>\nknowledge_graph = <test_gpt5_p7_knowledge.MockKnowledgeGraphManager object at 0x1b7d25460>\n\n    @pytest.mark.asyncio\n    async def test_cross_project_pattern_recognition(self, knowledge_graph):\n        \"\"\"Test recognition of patterns across different projects\"\"\"\n        await knowledge_graph.initialize()\n    \n        # Simulate entities from different projects but similar patterns\n        project_patterns = [\n            {\n                \"project\": \"project_A\",\n                \"pattern\": \"authentication_handler\",\n                \"entities\": [\"login_function\", \"validate_user\", \"generate_token\"]\n            },\n            {\n                \"project\": \"project_B\",\n                \"pattern\": \"authentication_handler\",\n                \"entities\": [\"authenticate\", \"check_credentials\", \"create_session\"]\n            }\n        ]\n    \n        all_entities = []\n        for project_data in project_patterns:\n            for entity_name in project_data[\"entities\"]:\n                entity = KnowledgeEntity(\n                    entity_id=f\"{project_data['project']}_{entity_name}\",\n                    name=entity_name,\n                    entity_type=KnowledgeEntityType.FUNCTION,\n                    properties={\n                        \"project\": project_data['project'],\n                        \"pattern\": project_data['pattern'],\n                        \"domain\": \"authentication\"\n                    },\n                    source_file=f\"{project_data['project']}/auth.py\"\n                )\n                await knowledge_graph.add_entity(entity)\n                all_entities.append(entity)\n    \n        # Find cross-project patterns\n        patterns = await knowledge_graph.find_patterns(\"code_pattern\")\n    \n        # Should identify authentication pattern across projects\n        auth_patterns = [p for p in patterns if \"auth\" in p.get('description', '').lower()]\n>       assert len(auth_patterns) > 0\nE       assert 0 > 0\nE        +  where 0 = len([])\n\ntests/unit/test_gpt5_p7_knowledge.py:1646: AssertionError\n____ TestKnowledgeTransferAndLearning.test_solution_pattern_generalization _____\n\nself = <test_gpt5_p7_knowledge.TestKnowledgeTransferAndLearning object at 0x134f3cdf0>\nknowledge_graph = <test_gpt5_p7_knowledge.MockKnowledgeGraphManager object at 0x18d150c40>\n\n    @pytest.mark.asyncio\n    async def test_solution_pattern_generalization(self, knowledge_graph):\n        \"\"\"Test generalization of solution patterns from specific instances\"\"\"\n        await knowledge_graph.initialize()\n    \n        # Create specific solution instances\n        solution_instances = [\n            {\n                \"name\": \"sql_injection_fix_1\",\n                \"problem\": \"SQL injection vulnerability\",\n                \"solution\": \"parameterized_queries\",\n                \"context\": \"user_authentication\"\n            },\n            {\n                \"name\": \"sql_injection_fix_2\",\n                \"problem\": \"SQL injection vulnerability\",\n                \"solution\": \"parameterized_queries\",\n                \"context\": \"data_retrieval\"\n            },\n            {\n                \"name\": \"sql_injection_fix_3\",\n                \"problem\": \"SQL injection vulnerability\",\n                \"solution\": \"input_validation_and_parameterized_queries\",\n                \"context\": \"reporting_system\"\n            }\n        ]\n    \n        for instance in solution_instances:\n            # Create problem entity\n            problem_entity = KnowledgeEntity(\n                entity_id=f\"problem_{instance['name']}\",\n                name=f\"problem_{instance['problem']}_{instance['context']}\",\n                entity_type=KnowledgeEntityType.BUG,\n                properties={\n                    \"problem_type\": instance['problem'],\n                    \"context\": instance['context']\n                }\n            )\n            await knowledge_graph.add_entity(problem_entity)\n    \n            # Create solution entity\n            solution_entity = KnowledgeEntity(\n                entity_id=f\"solution_{instance['name']}\",\n                name=instance['name'],\n                entity_type=KnowledgeEntityType.SOLUTION,\n                properties={\n                    \"solution_approach\": instance['solution'],\n                    \"context\": instance['context']\n                }\n            )\n            await knowledge_graph.add_entity(solution_entity)\n    \n            # Create fixes relationship\n            fixes_rel = KnowledgeRelationship(\n                relationship_id=f\"fixes_{instance['name']}\",\n                source_entity_id=solution_entity.entity_id,\n                target_entity_id=problem_entity.entity_id,\n                relationship_type=RelationshipType.FIXES,\n                properties={\"effectiveness\": \"high\"},\n                strength=0.9,\n                confidence=0.95\n            )\n            await knowledge_graph.add_relationship(fixes_rel)\n    \n        # Find generalized pattern\n        patterns = await knowledge_graph.find_patterns(\"code_pattern\")\n    \n        # Should identify common SQL injection solution pattern\n        sql_patterns = [p for p in patterns\n                       if \"sql\" in p.get('description', '').lower() or\n                          len(p.get('instances', [])) >= 3]\n>       assert len(sql_patterns) > 0\nE       assert 0 > 0\nE        +  where 0 = len([])\n\ntests/unit/test_gpt5_p7_knowledge.py:1776: AssertionError\n_________ TestDeploymentOrchestrator.test_deployment_config_validation _________\n\nself = <test_gpt5_p9_deployment.TestDeploymentOrchestrator object at 0x134f238e0>\ndeployment_orchestrator = <test_gpt5_p9_deployment.MockDeploymentOrchestrator object at 0x1a26b2760>\nsample_deployment_config = DeploymentConfig(deployment_id='test_deploy_001', application_name='myagent-api', version='v1.2.3', environment=<Envir...'}, rollback_enabled=True, max_deployment_duration=1800, health_check_endpoints=['/health', '/api/health', '/metrics'])\n\n    @pytest.mark.asyncio\n    async def test_deployment_config_validation(self, deployment_orchestrator, sample_deployment_config):\n        \"\"\"Test deployment configuration validation\"\"\"\n        await deployment_orchestrator.initialize()\n    \n        # Test valid configuration\n        validation_result = await deployment_orchestrator._validate_deployment_config(sample_deployment_config)\n        assert validation_result[\"valid\"] is True\n        assert len(validation_result[\"errors\"]) == 0\n    \n        # Test invalid configuration - missing application name\n>       invalid_config = DeploymentConfig(\n            deployment_id=\"invalid_deploy\",\n            application_name=\"\",  # Invalid: empty\n            version=\"v1.0.0\",\n            environment=Environment.DEVELOPMENT,\n            strategy=DeploymentStrategy.RECREATE,\n            quality_gates=[],\n            environment_config={}  # Invalid: missing required keys\n        )\nE       TypeError: __init__() missing 1 required positional argument: 'secrets'\n\ntests/unit/test_gpt5_p9_deployment.py:1198: TypeError\n_____________ TestDeploymentOrchestrator.test_deployment_creation ______________\n\nself = <test_gpt5_p9_deployment.TestDeploymentOrchestrator object at 0x134f237c0>\ndeployment_orchestrator = <test_gpt5_p9_deployment.MockDeploymentOrchestrator object at 0x1353b2370>\nsample_deployment_config = DeploymentConfig(deployment_id='test_deploy_001', application_name='myagent-api', version='v1.2.3', environment=<Envir...'}, rollback_enabled=True, max_deployment_duration=1800, health_check_endpoints=['/health', '/api/health', '/metrics'])\n\n    @pytest.mark.asyncio\n    async def test_deployment_creation(self, deployment_orchestrator, sample_deployment_config):\n        \"\"\"Test deployment creation\"\"\"\n        await deployment_orchestrator.initialize()\n    \n>       deployment_id = await deployment_orchestrator.create_deployment(sample_deployment_config)\n\ntests/unit/test_gpt5_p9_deployment.py:1236: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/unit/test_gpt5_p9_deployment.py:263: in create_deployment\n    execution.rollback_plan = await self._create_rollback_plan(config)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <test_gpt5_p9_deployment.MockDeploymentOrchestrator object at 0x1353b2370>\nconfig = DeploymentConfig(deployment_id='test_deploy_001', application_name='myagent-api', version='v1.2.3', environment=<Envir...'}, rollback_enabled=True, max_deployment_duration=1800, health_check_endpoints=['/health', '/api/health', '/metrics'])\n\n    async def _create_rollback_plan(self, config: DeploymentConfig) -> Dict[str, Any]:\n        \"\"\"Create rollback plan for deployment\"\"\"\n        return {\n            \"rollback_strategy\": \"previous_version\",\n>           \"rollback_version\": f\"v{float(config.version.replace('v', '')) - 0.1:.1f}\",\n            \"rollback_duration_estimate\": 300,  # 5 minutes\n            \"rollback_validation_steps\": [\n                \"health_check_validation\",\n                \"performance_baseline_validation\",\n                \"smoke_test_execution\"\n            ]\n        }\nE       ValueError: could not convert string to float: '1.2.3'\n\ntests/unit/test_gpt5_p9_deployment.py:869: ValueError\n___ TestDeploymentOrchestrator.test_deployment_creation_with_invalid_config ____\n\nself = <test_gpt5_p9_deployment.TestDeploymentOrchestrator object at 0x134f231f0>\ndeployment_orchestrator = <test_gpt5_p9_deployment.MockDeploymentOrchestrator object at 0x1a269dac0>\n\n    @pytest.mark.asyncio\n    async def test_deployment_creation_with_invalid_config(self, deployment_orchestrator):\n        \"\"\"Test deployment creation with invalid configuration\"\"\"\n        await deployment_orchestrator.initialize()\n    \n>       invalid_config = DeploymentConfig(\n            deployment_id=\"invalid_deploy\",\n            application_name=\"\",  # Invalid\n            version=\"v1.0.0\",\n            environment=Environment.DEVELOPMENT,\n            strategy=DeploymentStrategy.RECREATE,\n            quality_gates=[],\n            environment_config={}  # Invalid\n        )\nE       TypeError: __init__() missing 1 required positional argument: 'secrets'\n\ntests/unit/test_gpt5_p9_deployment.py:1253: TypeError\n____ TestDeploymentOrchestrator.test_deployment_pipeline_execution_success _____\n\nself = <test_gpt5_p9_deployment.TestDeploymentOrchestrator object at 0x134f23d60>\ndeployment_orchestrator = <test_gpt5_p9_deployment.MockDeploymentOrchestrator object at 0x18d4789d0>\nsample_deployment_config = DeploymentConfig(deployment_id='test_deploy_001', application_name='myagent-api', version='v1.2.3', environment=<Envir...'}, rollback_enabled=True, max_deployment_duration=1800, health_check_endpoints=['/health', '/api/health', '/metrics'])\n\n    @pytest.mark.asyncio\n    async def test_deployment_pipeline_execution_success(self, deployment_orchestrator, sample_deployment_config):\n        \"\"\"Test successful deployment pipeline execution\"\"\"\n        await deployment_orchestrator.initialize()\n    \n        # Create deployment\n>       deployment_id = await deployment_orchestrator.create_deployment(sample_deployment_config)\n\ntests/unit/test_gpt5_p9_deployment.py:1272: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/unit/test_gpt5_p9_deployment.py:263: in create_deployment\n    execution.rollback_plan = await self._create_rollback_plan(config)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <test_gpt5_p9_deployment.MockDeploymentOrchestrator object at 0x18d4789d0>\nconfig = DeploymentConfig(deployment_id='test_deploy_001', application_name='myagent-api', version='v1.2.3', environment=<Envir...'}, rollback_enabled=True, max_deployment_duration=1800, health_check_endpoints=['/health', '/api/health', '/metrics'])\n\n    async def _create_rollback_plan(self, config: DeploymentConfig) -> Dict[str, Any]:\n        \"\"\"Create rollback plan for deployment\"\"\"\n        return {\n            \"rollback_strategy\": \"previous_version\",\n>           \"rollback_version\": f\"v{float(config.version.replace('v', '')) - 0.1:.1f}\",\n            \"rollback_duration_estimate\": 300,  # 5 minutes\n            \"rollback_validation_steps\": [\n                \"health_check_validation\",\n                \"performance_baseline_validation\",\n                \"smoke_test_execution\"\n            ]\n        }\nE       ValueError: could not convert string to float: '1.2.3'\n\ntests/unit/test_gpt5_p9_deployment.py:869: ValueError\n__________ TestDeploymentOrchestrator.test_quality_gates_integration ___________\n\nself = <test_gpt5_p9_deployment.TestDeploymentOrchestrator object at 0x134dca670>\ndeployment_orchestrator = <test_gpt5_p9_deployment.MockDeploymentOrchestrator object at 0x1724ced90>\nsample_deployment_config = DeploymentConfig(deployment_id='test_deploy_001', application_name='myagent-api', version='v1.2.3', environment=<Envir...'}, rollback_enabled=True, max_deployment_duration=1800, health_check_endpoints=['/health', '/api/health', '/metrics'])\n\n    @pytest.mark.asyncio\n    async def test_quality_gates_integration(self, deployment_orchestrator, sample_deployment_config):\n        \"\"\"Test quality gates integration with pipeline\"\"\"\n        await deployment_orchestrator.initialize()\n    \n        # Create deployment\n>       deployment_id = await deployment_orchestrator.create_deployment(sample_deployment_config)\n\ntests/unit/test_gpt5_p9_deployment.py:1353: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/unit/test_gpt5_p9_deployment.py:263: in create_deployment\n    execution.rollback_plan = await self._create_rollback_plan(config)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <test_gpt5_p9_deployment.MockDeploymentOrchestrator object at 0x1724ced90>\nconfig = DeploymentConfig(deployment_id='test_deploy_001', application_name='myagent-api', version='v1.2.3', environment=<Envir...'}, rollback_enabled=True, max_deployment_duration=1800, health_check_endpoints=['/health', '/api/health', '/metrics'])\n\n    async def _create_rollback_plan(self, config: DeploymentConfig) -> Dict[str, Any]:\n        \"\"\"Create rollback plan for deployment\"\"\"\n        return {\n            \"rollback_strategy\": \"previous_version\",\n>           \"rollback_version\": f\"v{float(config.version.replace('v', '')) - 0.1:.1f}\",\n            \"rollback_duration_estimate\": 300,  # 5 minutes\n            \"rollback_validation_steps\": [\n                \"health_check_validation\",\n                \"performance_baseline_validation\",\n                \"smoke_test_execution\"\n            ]\n        }\nE       ValueError: could not convert string to float: '1.2.3'\n\ntests/unit/test_gpt5_p9_deployment.py:869: ValueError\n________ TestDeploymentOrchestrator.test_deployment_rollback_on_failure ________\n\nself = <test_gpt5_p9_deployment.TestDeploymentOrchestrator object at 0x134dcaac0>\ndeployment_orchestrator = <test_gpt5_p9_deployment.MockDeploymentOrchestrator object at 0x171a6e7c0>\nsample_deployment_config = DeploymentConfig(deployment_id='test_deploy_001', application_name='myagent-api', version='v1.2.3', environment=<Envir...'}, rollback_enabled=True, max_deployment_duration=1800, health_check_endpoints=['/health', '/api/health', '/metrics'])\n\n    @pytest.mark.asyncio\n    async def test_deployment_rollback_on_failure(self, deployment_orchestrator, sample_deployment_config):\n        \"\"\"Test deployment rollback on pipeline failure\"\"\"\n        await deployment_orchestrator.initialize()\n    \n        # Create quality gate that will fail\n        failing_gate = QualityGate(\n            name=\"test_coverage\",\n            threshold=99.0,  # Very high threshold that will fail\n            description=\"Test coverage must be 99%\",\n            blocking=True\n        )\n        sample_deployment_config.quality_gates = [failing_gate]\n    \n        # Create deployment\n>       deployment_id = await deployment_orchestrator.create_deployment(sample_deployment_config)\n\ntests/unit/test_gpt5_p9_deployment.py:1386: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/unit/test_gpt5_p9_deployment.py:263: in create_deployment\n    execution.rollback_plan = await self._create_rollback_plan(config)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <test_gpt5_p9_deployment.MockDeploymentOrchestrator object at 0x171a6e7c0>\nconfig = DeploymentConfig(deployment_id='test_deploy_001', application_name='myagent-api', version='v1.2.3', environment=<Envir...'}, rollback_enabled=True, max_deployment_duration=1800, health_check_endpoints=['/health', '/api/health', '/metrics'])\n\n    async def _create_rollback_plan(self, config: DeploymentConfig) -> Dict[str, Any]:\n        \"\"\"Create rollback plan for deployment\"\"\"\n        return {\n            \"rollback_strategy\": \"previous_version\",\n>           \"rollback_version\": f\"v{float(config.version.replace('v', '')) - 0.1:.1f}\",\n            \"rollback_duration_estimate\": 300,  # 5 minutes\n            \"rollback_validation_steps\": [\n                \"health_check_validation\",\n                \"performance_baseline_validation\",\n                \"smoke_test_execution\"\n            ]\n        }\nE       ValueError: could not convert string to float: '1.2.3'\n\ntests/unit/test_gpt5_p9_deployment.py:869: ValueError\n___________ TestDeploymentOrchestrator.test_deployment_cancellation ____________\n\nself = <test_gpt5_p9_deployment.TestDeploymentOrchestrator object at 0x134dcadc0>\ndeployment_orchestrator = <test_gpt5_p9_deployment.MockDeploymentOrchestrator object at 0x15f45b370>\nsample_deployment_config = DeploymentConfig(deployment_id='test_deploy_001', application_name='myagent-api', version='v1.2.3', environment=<Envir...'}, rollback_enabled=True, max_deployment_duration=1800, health_check_endpoints=['/health', '/api/health', '/metrics'])\n\n    @pytest.mark.asyncio\n    async def test_deployment_cancellation(self, deployment_orchestrator, sample_deployment_config):\n        \"\"\"Test deployment cancellation\"\"\"\n        await deployment_orchestrator.initialize()\n    \n        # Create deployment\n>       deployment_id = await deployment_orchestrator.create_deployment(sample_deployment_config)\n\ntests/unit/test_gpt5_p9_deployment.py:1402: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/unit/test_gpt5_p9_deployment.py:263: in create_deployment\n    execution.rollback_plan = await self._create_rollback_plan(config)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <test_gpt5_p9_deployment.MockDeploymentOrchestrator object at 0x15f45b370>\nconfig = DeploymentConfig(deployment_id='test_deploy_001', application_name='myagent-api', version='v1.2.3', environment=<Envir...'}, rollback_enabled=True, max_deployment_duration=1800, health_check_endpoints=['/health', '/api/health', '/metrics'])\n\n    async def _create_rollback_plan(self, config: DeploymentConfig) -> Dict[str, Any]:\n        \"\"\"Create rollback plan for deployment\"\"\"\n        return {\n            \"rollback_strategy\": \"previous_version\",\n>           \"rollback_version\": f\"v{float(config.version.replace('v', '')) - 0.1:.1f}\",\n            \"rollback_duration_estimate\": 300,  # 5 minutes\n            \"rollback_validation_steps\": [\n                \"health_check_validation\",\n                \"performance_baseline_validation\",\n                \"smoke_test_execution\"\n            ]\n        }\nE       ValueError: could not convert string to float: '1.2.3'\n\ntests/unit/test_gpt5_p9_deployment.py:869: ValueError\n______________ TestDeploymentOrchestrator.test_deployment_scaling ______________\n\nself = <test_gpt5_p9_deployment.TestDeploymentOrchestrator object at 0x134db4070>\ndeployment_orchestrator = <test_gpt5_p9_deployment.MockDeploymentOrchestrator object at 0x16054e670>\nsample_deployment_config = DeploymentConfig(deployment_id='test_deploy_001', application_name='myagent-api', version='v1.2.3', environment=<Envir...'}, rollback_enabled=True, max_deployment_duration=1800, health_check_endpoints=['/health', '/api/health', '/metrics'])\n\n    @pytest.mark.asyncio\n    async def test_deployment_scaling(self, deployment_orchestrator, sample_deployment_config):\n        \"\"\"Test deployment scaling\"\"\"\n        await deployment_orchestrator.initialize()\n    \n        # Create and execute deployment first\n>       deployment_id = await deployment_orchestrator.create_deployment(sample_deployment_config)\n\ntests/unit/test_gpt5_p9_deployment.py:1436: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/unit/test_gpt5_p9_deployment.py:263: in create_deployment\n    execution.rollback_plan = await self._create_rollback_plan(config)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <test_gpt5_p9_deployment.MockDeploymentOrchestrator object at 0x16054e670>\nconfig = DeploymentConfig(deployment_id='test_deploy_001', application_name='myagent-api', version='v1.2.3', environment=<Envir...'}, rollback_enabled=True, max_deployment_duration=1800, health_check_endpoints=['/health', '/api/health', '/metrics'])\n\n    async def _create_rollback_plan(self, config: DeploymentConfig) -> Dict[str, Any]:\n        \"\"\"Create rollback plan for deployment\"\"\"\n        return {\n            \"rollback_strategy\": \"previous_version\",\n>           \"rollback_version\": f\"v{float(config.version.replace('v', '')) - 0.1:.1f}\",\n            \"rollback_duration_estimate\": 300,  # 5 minutes\n            \"rollback_validation_steps\": [\n                \"health_check_validation\",\n                \"performance_baseline_validation\",\n                \"smoke_test_execution\"\n            ]\n        }\nE       ValueError: could not convert string to float: '1.2.3'\n\ntests/unit/test_gpt5_p9_deployment.py:869: ValueError\n________ TestDeploymentOrchestrator.test_deployment_metrics_collection _________\n\nself = <test_gpt5_p9_deployment.TestDeploymentOrchestrator object at 0x134db4310>\ndeployment_orchestrator = <test_gpt5_p9_deployment.MockDeploymentOrchestrator object at 0x159af9fa0>\nsample_deployment_config = DeploymentConfig(deployment_id='test_deploy_001', application_name='myagent-api', version='v1.2.3', environment=<Envir...'}, rollback_enabled=True, max_deployment_duration=1800, health_check_endpoints=['/health', '/api/health', '/metrics'])\n\n    @pytest.mark.asyncio\n    async def test_deployment_metrics_collection(self, deployment_orchestrator, sample_deployment_config):\n        \"\"\"Test deployment metrics collection\"\"\"\n        await deployment_orchestrator.initialize()\n    \n        # Create and execute deployment\n>       deployment_id = await deployment_orchestrator.create_deployment(sample_deployment_config)\n\ntests/unit/test_gpt5_p9_deployment.py:1453: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/unit/test_gpt5_p9_deployment.py:263: in create_deployment\n    execution.rollback_plan = await self._create_rollback_plan(config)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <test_gpt5_p9_deployment.MockDeploymentOrchestrator object at 0x159af9fa0>\nconfig = DeploymentConfig(deployment_id='test_deploy_001', application_name='myagent-api', version='v1.2.3', environment=<Envir...'}, rollback_enabled=True, max_deployment_duration=1800, health_check_endpoints=['/health', '/api/health', '/metrics'])\n\n    async def _create_rollback_plan(self, config: DeploymentConfig) -> Dict[str, Any]:\n        \"\"\"Create rollback plan for deployment\"\"\"\n        return {\n            \"rollback_strategy\": \"previous_version\",\n>           \"rollback_version\": f\"v{float(config.version.replace('v', '')) - 0.1:.1f}\",\n            \"rollback_duration_estimate\": 300,  # 5 minutes\n            \"rollback_validation_steps\": [\n                \"health_check_validation\",\n                \"performance_baseline_validation\",\n                \"smoke_test_execution\"\n            ]\n        }\nE       ValueError: could not convert string to float: '1.2.3'\n\ntests/unit/test_gpt5_p9_deployment.py:869: ValueError\n_________ TestDeploymentOrchestrator.test_deployment_status_retrieval __________\n\nself = <test_gpt5_p9_deployment.TestDeploymentOrchestrator object at 0x134db4820>\ndeployment_orchestrator = <test_gpt5_p9_deployment.MockDeploymentOrchestrator object at 0x18d47a1c0>\nsample_deployment_config = DeploymentConfig(deployment_id='test_deploy_001', application_name='myagent-api', version='v1.2.3', environment=<Envir...'}, rollback_enabled=True, max_deployment_duration=1800, health_check_endpoints=['/health', '/api/health', '/metrics'])\n\n    @pytest.mark.asyncio\n    async def test_deployment_status_retrieval(self, deployment_orchestrator, sample_deployment_config):\n        \"\"\"Test deployment status retrieval\"\"\"\n        await deployment_orchestrator.initialize()\n    \n        # Create deployment\n>       deployment_id = await deployment_orchestrator.create_deployment(sample_deployment_config)\n\ntests/unit/test_gpt5_p9_deployment.py:1521: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/unit/test_gpt5_p9_deployment.py:263: in create_deployment\n    execution.rollback_plan = await self._create_rollback_plan(config)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <test_gpt5_p9_deployment.MockDeploymentOrchestrator object at 0x18d47a1c0>\nconfig = DeploymentConfig(deployment_id='test_deploy_001', application_name='myagent-api', version='v1.2.3', environment=<Envir...'}, rollback_enabled=True, max_deployment_duration=1800, health_check_endpoints=['/health', '/api/health', '/metrics'])\n\n    async def _create_rollback_plan(self, config: DeploymentConfig) -> Dict[str, Any]:\n        \"\"\"Create rollback plan for deployment\"\"\"\n        return {\n            \"rollback_strategy\": \"previous_version\",\n>           \"rollback_version\": f\"v{float(config.version.replace('v', '')) - 0.1:.1f}\",\n            \"rollback_duration_estimate\": 300,  # 5 minutes\n            \"rollback_validation_steps\": [\n                \"health_check_validation\",\n                \"performance_baseline_validation\",\n                \"smoke_test_execution\"\n            ]\n        }\nE       ValueError: could not convert string to float: '1.2.3'\n\ntests/unit/test_gpt5_p9_deployment.py:869: ValueError\n_____ TestDeploymentOrchestrator.test_deployment_with_different_strategies _____\n\nself = <test_gpt5_p9_deployment.TestDeploymentOrchestrator object at 0x134db4ac0>\ndeployment_orchestrator = <test_gpt5_p9_deployment.MockDeploymentOrchestrator object at 0x159b84940>\nsample_deployment_config = DeploymentConfig(deployment_id='deploy_blue_green', application_name='myagent-api', version='v1.2.3', environment=<Env...'}, rollback_enabled=True, max_deployment_duration=1800, health_check_endpoints=['/health', '/api/health', '/metrics'])\n\n    @pytest.mark.asyncio\n    async def test_deployment_with_different_strategies(self, deployment_orchestrator, sample_deployment_config):\n        \"\"\"Test deployment with different deployment strategies\"\"\"\n        await deployment_orchestrator.initialize()\n    \n        strategies = [\n            DeploymentStrategy.BLUE_GREEN,\n            DeploymentStrategy.ROLLING_UPDATE,\n            DeploymentStrategy.CANARY\n        ]\n    \n        for strategy in strategies:\n            # Configure deployment with strategy\n            sample_deployment_config.deployment_id = f\"deploy_{strategy.value}\"\n            sample_deployment_config.strategy = strategy\n            sample_deployment_config.environment = Environment.PRODUCTION\n    \n            # Create and execute deployment\n>           deployment_id = await deployment_orchestrator.create_deployment(sample_deployment_config)\n\ntests/unit/test_gpt5_p9_deployment.py:1552: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/unit/test_gpt5_p9_deployment.py:263: in create_deployment\n    execution.rollback_plan = await self._create_rollback_plan(config)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <test_gpt5_p9_deployment.MockDeploymentOrchestrator object at 0x159b84940>\nconfig = DeploymentConfig(deployment_id='deploy_blue_green', application_name='myagent-api', version='v1.2.3', environment=<Env...'}, rollback_enabled=True, max_deployment_duration=1800, health_check_endpoints=['/health', '/api/health', '/metrics'])\n\n    async def _create_rollback_plan(self, config: DeploymentConfig) -> Dict[str, Any]:\n        \"\"\"Create rollback plan for deployment\"\"\"\n        return {\n            \"rollback_strategy\": \"previous_version\",\n>           \"rollback_version\": f\"v{float(config.version.replace('v', '')) - 0.1:.1f}\",\n            \"rollback_duration_estimate\": 300,  # 5 minutes\n            \"rollback_validation_steps\": [\n                \"health_check_validation\",\n                \"performance_baseline_validation\",\n                \"smoke_test_execution\"\n            ]\n        }\nE       ValueError: could not convert string to float: '1.2.3'\n\ntests/unit/test_gpt5_p9_deployment.py:869: ValueError\n____________ TestDeploymentOrchestrator.test_concurrent_deployments ____________\n\nself = <test_gpt5_p9_deployment.TestDeploymentOrchestrator object at 0x134dcaee0>\ndeployment_orchestrator = <test_gpt5_p9_deployment.MockDeploymentOrchestrator object at 0x172602b50>\n\n    @pytest.mark.asyncio\n    async def test_concurrent_deployments(self, deployment_orchestrator):\n        \"\"\"Test handling of concurrent deployments\"\"\"\n        await deployment_orchestrator.initialize()\n    \n        # Create multiple deployment configs\n        configs = []\n        for i in range(3):\n>           config = DeploymentConfig(\n                deployment_id=f\"concurrent_deploy_{i}\",\n                application_name=f\"app_{i}\",\n                version=f\"v1.{i}.0\",\n                environment=Environment.DEVELOPMENT,\n                strategy=DeploymentStrategy.RECREATE,\n                quality_gates=[],\n                environment_config={\n                    \"replicas\": 1,\n                    \"cpu_limit\": \"500m\",\n                    \"memory_limit\": \"512Mi\"\n                }\n            )\nE           TypeError: __init__() missing 1 required positional argument: 'secrets'\n\ntests/unit/test_gpt5_p9_deployment.py:1576: TypeError\n_________ TestDeploymentOrchestrator.test_deployment_timeout_handling __________\n\nself = <test_gpt5_p9_deployment.TestDeploymentOrchestrator object at 0x134dca550>\ndeployment_orchestrator = <test_gpt5_p9_deployment.MockDeploymentOrchestrator object at 0x135241d30>\nsample_deployment_config = DeploymentConfig(deployment_id='test_deploy_001', application_name='myagent-api', version='v1.2.3', environment=<Envir...key'}, rollback_enabled=True, max_deployment_duration=1, health_check_endpoints=['/health', '/api/health', '/metrics'])\n\n    @pytest.mark.asyncio\n    async def test_deployment_timeout_handling(self, deployment_orchestrator, sample_deployment_config):\n        \"\"\"Test deployment timeout handling\"\"\"\n        await deployment_orchestrator.initialize()\n    \n        # Set very short timeout\n        sample_deployment_config.max_deployment_duration = 1  # 1 second\n    \n        # Create deployment\n>       deployment_id = await deployment_orchestrator.create_deployment(sample_deployment_config)\n\ntests/unit/test_gpt5_p9_deployment.py:1620: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/unit/test_gpt5_p9_deployment.py:263: in create_deployment\n    execution.rollback_plan = await self._create_rollback_plan(config)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <test_gpt5_p9_deployment.MockDeploymentOrchestrator object at 0x135241d30>\nconfig = DeploymentConfig(deployment_id='test_deploy_001', application_name='myagent-api', version='v1.2.3', environment=<Envir...key'}, rollback_enabled=True, max_deployment_duration=1, health_check_endpoints=['/health', '/api/health', '/metrics'])\n\n    async def _create_rollback_plan(self, config: DeploymentConfig) -> Dict[str, Any]:\n        \"\"\"Create rollback plan for deployment\"\"\"\n        return {\n            \"rollback_strategy\": \"previous_version\",\n>           \"rollback_version\": f\"v{float(config.version.replace('v', '')) - 0.1:.1f}\",\n            \"rollback_duration_estimate\": 300,  # 5 minutes\n            \"rollback_validation_steps\": [\n                \"health_check_validation\",\n                \"performance_baseline_validation\",\n                \"smoke_test_execution\"\n            ]\n        }\nE       ValueError: could not convert string to float: '1.2.3'\n\ntests/unit/test_gpt5_p9_deployment.py:869: ValueError\n__________ TestDeploymentOrchestrator.test_post_deployment_validation __________\n\nself = <test_gpt5_p9_deployment.TestDeploymentOrchestrator object at 0x134f23910>\ndeployment_orchestrator = <test_gpt5_p9_deployment.MockDeploymentOrchestrator object at 0x17fc924c0>\nsample_deployment_config = DeploymentConfig(deployment_id='test_deploy_001', application_name='myagent-api', version='v1.2.3', environment=<Envir...ging_api_key'}, rollback_enabled=True, max_deployment_duration=1800, health_check_endpoints=['/health', '/api/status'])\n\n    @pytest.mark.asyncio\n    async def test_post_deployment_validation(self, deployment_orchestrator, sample_deployment_config):\n        \"\"\"Test post-deployment validation\"\"\"\n        await deployment_orchestrator.initialize()\n    \n        # Set up production deployment with validation\n        sample_deployment_config.environment = Environment.PRODUCTION\n        sample_deployment_config.health_check_endpoints = [\"/health\", \"/api/status\"]\n    \n        # Create and execute deployment\n>       deployment_id = await deployment_orchestrator.create_deployment(sample_deployment_config)\n\ntests/unit/test_gpt5_p9_deployment.py:1637: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/unit/test_gpt5_p9_deployment.py:263: in create_deployment\n    execution.rollback_plan = await self._create_rollback_plan(config)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <test_gpt5_p9_deployment.MockDeploymentOrchestrator object at 0x17fc924c0>\nconfig = DeploymentConfig(deployment_id='test_deploy_001', application_name='myagent-api', version='v1.2.3', environment=<Envir...ging_api_key'}, rollback_enabled=True, max_deployment_duration=1800, health_check_endpoints=['/health', '/api/status'])\n\n    async def _create_rollback_plan(self, config: DeploymentConfig) -> Dict[str, Any]:\n        \"\"\"Create rollback plan for deployment\"\"\"\n        return {\n            \"rollback_strategy\": \"previous_version\",\n>           \"rollback_version\": f\"v{float(config.version.replace('v', '')) - 0.1:.1f}\",\n            \"rollback_duration_estimate\": 300,  # 5 minutes\n            \"rollback_validation_steps\": [\n                \"health_check_validation\",\n                \"performance_baseline_validation\",\n                \"smoke_test_execution\"\n            ]\n        }\nE       ValueError: could not convert string to float: '1.2.3'\n\ntests/unit/test_gpt5_p9_deployment.py:869: ValueError\n____ TestDeploymentPipelineIntegration.test_pipeline_stages_from_test_data _____\n\nself = <test_gpt5_p9_deployment.TestDeploymentPipelineIntegration object at 0x134db4760>\ndeployment_orchestrator = <test_gpt5_p9_deployment.MockDeploymentOrchestrator object at 0x18d47a4c0>\ngpt5_test_data = {'deployment_strategies': ['rolling_update', 'blue_green', 'canary'], 'pipeline_stages': ['code_checkout', 'dependency..., 'threshold': 85.0}, {'name': 'security_score', 'threshold': 95.0}, {'name': 'performance_score', 'threshold': 90.0}]}\n\n    @pytest.mark.asyncio\n    async def test_pipeline_stages_from_test_data(self, deployment_orchestrator, gpt5_test_data):\n        \"\"\"Test pipeline stages configuration from test data\"\"\"\n        if not gpt5_test_data or 'pipeline_stages' not in gpt5_test_data:\n            pytest.skip(\"GPT-5 deployment test data not available\")\n    \n        await deployment_orchestrator.initialize()\n    \n        expected_stages = gpt5_test_data['pipeline_stages']\n    \n        # Create deployment config\n>       config = DeploymentConfig(\n            deployment_id=\"pipeline_test\",\n            application_name=\"test_app\",\n            version=\"v1.0.0\",\n            environment=Environment.PRODUCTION,\n            strategy=DeploymentStrategy.BLUE_GREEN,\n            quality_gates=[],\n            environment_config={\"replicas\": 1, \"cpu_limit\": \"1000m\", \"memory_limit\": \"1Gi\"}\n        )\nE       TypeError: __init__() missing 1 required positional argument: 'secrets'\n\ntests/unit/test_gpt5_p9_deployment.py:1674: TypeError\n_____ TestDeploymentPipelineIntegration.test_quality_gates_from_test_data ______\n\nself = <test_gpt5_p9_deployment.TestDeploymentPipelineIntegration object at 0x134db41c0>\ndeployment_orchestrator = <test_gpt5_p9_deployment.MockDeploymentOrchestrator object at 0x18d2cd4f0>\ngpt5_test_data = {'deployment_strategies': ['rolling_update', 'blue_green', 'canary'], 'pipeline_stages': ['code_checkout', 'dependency..., 'threshold': 85.0}, {'name': 'security_score', 'threshold': 95.0}, {'name': 'performance_score', 'threshold': 90.0}]}\n\n    @pytest.mark.asyncio\n    async def test_quality_gates_from_test_data(self, deployment_orchestrator, gpt5_test_data):\n        \"\"\"Test quality gates configuration from test data\"\"\"\n        if not gpt5_test_data or 'quality_gates' not in gpt5_test_data:\n            pytest.skip(\"GPT-5 deployment test data not available\")\n    \n        await deployment_orchestrator.initialize()\n    \n        test_gates_data = gpt5_test_data['quality_gates']\n    \n        # Create quality gates from test data\n        quality_gates = []\n        for gate_data in test_gates_data:\n            gate = QualityGate(\n                name=gate_data['name'],\n                threshold=gate_data['threshold'],\n                description=f\"Quality gate for {gate_data['name']}\",\n                blocking=True\n            )\n            quality_gates.append(gate)\n    \n        # Create deployment with test data quality gates\n>       config = DeploymentConfig(\n            deployment_id=\"quality_gate_test\",\n            application_name=\"test_app\",\n            version=\"v1.0.0\",\n            environment=Environment.STAGING,\n            strategy=DeploymentStrategy.ROLLING_UPDATE,\n            quality_gates=quality_gates,\n            environment_config={\"replicas\": 2, \"cpu_limit\": \"1000m\", \"memory_limit\": \"1Gi\"}\n        )\nE       TypeError: __init__() missing 1 required positional argument: 'secrets'\n\ntests/unit/test_gpt5_p9_deployment.py:1714: TypeError\n_ TestDeploymentPipelineIntegration.test_deployment_strategies_from_test_data __\n\nself = <test_gpt5_p9_deployment.TestDeploymentPipelineIntegration object at 0x134db4d90>\ndeployment_orchestrator = <test_gpt5_p9_deployment.MockDeploymentOrchestrator object at 0x159d3d2e0>\ngpt5_test_data = {'deployment_strategies': ['rolling_update', 'blue_green', 'canary'], 'pipeline_stages': ['code_checkout', 'dependency..., 'threshold': 85.0}, {'name': 'security_score', 'threshold': 95.0}, {'name': 'performance_score', 'threshold': 90.0}]}\n\n    @pytest.mark.asyncio\n    async def test_deployment_strategies_from_test_data(self, deployment_orchestrator, gpt5_test_data):\n        \"\"\"Test deployment strategies from test data\"\"\"\n        if not gpt5_test_data or 'deployment_strategies' not in gpt5_test_data:\n            pytest.skip(\"GPT-5 deployment test data not available\")\n    \n        await deployment_orchestrator.initialize()\n    \n        test_strategies = gpt5_test_data['deployment_strategies']\n    \n        for strategy_name in test_strategies:\n            # Map string to enum\n            strategy_mapping = {\n                \"rolling_update\": DeploymentStrategy.ROLLING_UPDATE,\n                \"blue_green\": DeploymentStrategy.BLUE_GREEN,\n                \"canary\": DeploymentStrategy.CANARY\n            }\n    \n            if strategy_name not in strategy_mapping:\n                continue\n    \n            strategy = strategy_mapping[strategy_name]\n    \n            # Create deployment with strategy\n>           config = DeploymentConfig(\n                deployment_id=f\"strategy_test_{strategy_name}\",\n                application_name=\"test_app\",\n                version=\"v1.0.0\",\n                environment=Environment.PRODUCTION,\n                strategy=strategy,\n                quality_gates=[],\n                environment_config={\"replicas\": 3, \"cpu_limit\": \"1000m\", \"memory_limit\": \"1Gi\"}\n            )\nE           TypeError: __init__() missing 1 required positional argument: 'secrets'\n\ntests/unit/test_gpt5_p9_deployment.py:1765: TypeError\n_ TestDeploymentPipelineIntegration.test_multi_environment_deployment_workflow _\n\nself = <test_gpt5_p9_deployment.TestDeploymentPipelineIntegration object at 0x134da26a0>\ndeployment_orchestrator = <test_gpt5_p9_deployment.MockDeploymentOrchestrator object at 0x159aaa400>\nsample_deployment_config = DeploymentConfig(deployment_id='test_deploy_001', application_name='myagent-api', version='v1.2.3', environment=<Envir...'}, rollback_enabled=True, max_deployment_duration=1800, health_check_endpoints=['/health', '/api/health', '/metrics'])\n\n    @pytest.mark.asyncio\n    async def test_multi_environment_deployment_workflow(self, deployment_orchestrator, sample_deployment_config):\n        \"\"\"Test complete multi-environment deployment workflow\"\"\"\n        await deployment_orchestrator.initialize()\n    \n        environments = [Environment.DEVELOPMENT, Environment.STAGING, Environment.PRODUCTION]\n        deployment_results = {}\n    \n        for env in environments:\n            # Configure for environment\n>           config = DeploymentConfig(\n                deployment_id=f\"multi_env_{env.value}\",\n                application_name=\"myagent-api\",\n                version=\"v1.2.3\",\n                environment=env,\n                strategy=DeploymentStrategy.ROLLING_UPDATE if env == Environment.PRODUCTION else DeploymentStrategy.RECREATE,\n                quality_gates=sample_deployment_config.quality_gates,\n                environment_config=deployment_orchestrator.environment_configs[env]\n            )\nE           TypeError: __init__() missing 1 required positional argument: 'secrets'\n\ntests/unit/test_gpt5_p9_deployment.py:1790: TypeError\n=============================== warnings summary ===============================\nvenv/lib/python3.9/site-packages/jupyter_client/connect.py:22\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/venv/lib/python3.9/site-packages/jupyter_client/connect.py:22: DeprecationWarning: Jupyter is migrating its paths to use standard platformdirs\n  given by the platformdirs library.  To remove this warning and\n  see the appropriate new directories, set the environment variable\n  `JUPYTER_PLATFORM_DIRS=1` and then run `jupyter --paths`.\n  The use of platformdirs will be the default in `jupyter_core` v6\n    from jupyter_core.paths import jupyter_data_dir, jupyter_runtime_dir, secure_write\n\nvenv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n\nconfig/settings.py:19\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:19: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    DEBUG: bool = Field(default=False, env=\"DEBUG\")\n\nconfig/settings.py:22\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:22: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    API_HOST: str = Field(default=\"0.0.0.0\", env=\"API_HOST\")\n\nconfig/settings.py:23\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:23: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    API_PORT: int = Field(default=8000, env=\"API_PORT\")\n\nconfig/settings.py:24\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:24: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    API_WORKERS: int = Field(default=4, env=\"API_WORKERS\")\n\nconfig/settings.py:25\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:25: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    CORS_ORIGINS: List[str] = Field(\n\nconfig/settings.py:31\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:31: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    DATABASE_URL: str = Field(\n\nconfig/settings.py:35\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:35: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    DATABASE_POOL_SIZE: int = Field(default=20, env=\"DATABASE_POOL_SIZE\")\n\nconfig/settings.py:36\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:36: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    DATABASE_MAX_OVERFLOW: int = Field(default=10, env=\"DATABASE_MAX_OVERFLOW\")\n\nconfig/settings.py:39\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:39: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    REDIS_URL: str = Field(default=\"redis://localhost:6379/0\", env=\"REDIS_URL\")\n\nconfig/settings.py:40\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:40: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    REDIS_MAX_CONNECTIONS: int = Field(default=50, env=\"REDIS_MAX_CONNECTIONS\")\n\nconfig/settings.py:42\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:42: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    @validator(\"DATABASE_URL\", pre=True, always=True)\n\nconfig/settings.py:55\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:55: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    CHROMADB_HOST: str = Field(default=\"localhost\", env=\"CHROMADB_HOST\")\n\nconfig/settings.py:56\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:56: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    CHROMADB_PORT: int = Field(default=8000, env=\"CHROMADB_PORT\")\n\nconfig/settings.py:57\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:57: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    CHROMADB_PATH: str = Field(\n\nconfig/settings.py:63\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:63: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    OPENAI_API_KEY: Optional[str] = Field(default=None, env=\"OPENAI_API_KEY\")\n\nconfig/settings.py:64\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:64: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    ANTHROPIC_API_KEY: Optional[str] = Field(default=None, env=\"ANTHROPIC_API_KEY\")\n\nconfig/settings.py:65\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:65: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    OLLAMA_BASE_URL: str = Field(\n\nconfig/settings.py:71\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:71: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    DEFAULT_LLM_PROVIDER: str = Field(default=\"openai\", env=\"DEFAULT_LLM_PROVIDER\")\n\nconfig/settings.py:72\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:72: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    DEFAULT_MODEL: str = Field(default=\"gpt-5-chat-latest\", env=\"DEFAULT_MODEL\")\n\nconfig/settings.py:73\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:73: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    LLM_TEMPERATURE: float = Field(default=0.7, env=\"LLM_TEMPERATURE\")\n\nconfig/settings.py:74\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:74: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    LLM_MAX_TOKENS: int = Field(default=2000, env=\"LLM_MAX_TOKENS\")\n\nconfig/settings.py:77\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:77: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    TARGET_TEST_COVERAGE: float = Field(default=95.0, env=\"TARGET_TEST_COVERAGE\")\n\nconfig/settings.py:78\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:78: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    TARGET_PERFORMANCE_SCORE: float = Field(\n\nconfig/settings.py:82\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:82: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    TARGET_DOCUMENTATION_COVERAGE: float = Field(\n\nconfig/settings.py:86\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:86: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    TARGET_CODE_QUALITY_SCORE: float = Field(\n\nconfig/settings.py:90\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:90: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    TARGET_SECURITY_SCORE: float = Field(default=95.0, env=\"TARGET_SECURITY_SCORE\")\n\nconfig/settings.py:91\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:91: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    TARGET_USER_SATISFACTION: float = Field(\n\nconfig/settings.py:97\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:97: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    MAX_AGENT_RETRIES: int = Field(default=3, env=\"MAX_AGENT_RETRIES\")\n\nconfig/settings.py:98\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:98: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    AGENT_TIMEOUT_SECONDS: int = Field(default=300, env=\"AGENT_TIMEOUT_SECONDS\")\n\nconfig/settings.py:99\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:99: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    CHECKPOINT_INTERVAL_HOURS: int = Field(\n\nconfig/settings.py:105\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:105: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    PERSISTENCE_DIR: Path = Field(\n\nconfig/settings.py:109\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:109: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    LOGS_DIR: Path = Field(default=Path(\"logs\"), env=\"LOGS_DIR\")\n\nconfig/settings.py:112\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:112: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    SECRET_KEY: str = Field(\n\nconfig/settings.py:116\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:116: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    JWT_ALGORITHM: str = Field(default=\"HS256\", env=\"JWT_ALGORITHM\")\n\nconfig/settings.py:117\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:117: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    JWT_EXPIRATION_MINUTES: int = Field(\n\nconfig/settings.py:123\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:123: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    RATE_LIMIT_PER_MINUTE: int = Field(default=100, env=\"RATE_LIMIT_PER_MINUTE\")\n\nconfig/settings.py:125\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:125: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    @validator(\"CORS_ORIGINS\", pre=True)\n\nconfig/settings.py:132\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:132: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    @validator(\"PERSISTENCE_DIR\", \"LOGS_DIR\", pre=True)\n\nconfig/settings.py:13\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:13: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    class Settings(BaseSettings):\n\ntests/unit/test_gpt5_p4_memory.py:23\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/tests/unit/test_gpt5_p4_memory.py:23: PytestUnknownMarkWarning: Unknown pytest.mark.unit - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.unit\n\ntests/unit/test_gpt5_p4_memory.py:24\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/tests/unit/test_gpt5_p4_memory.py:24: PytestUnknownMarkWarning: Unknown pytest.mark.gpt5 - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.gpt5\n\ntests/unit/test_gpt5_p4_memory.py:25\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/tests/unit/test_gpt5_p4_memory.py:25: PytestUnknownMarkWarning: Unknown pytest.mark.memory - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.memory\n\ntests/unit/test_gpt5_p4_memory.py:591\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/tests/unit/test_gpt5_p4_memory.py:591: PytestUnknownMarkWarning: Unknown pytest.mark.unit - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.unit\n\ntests/unit/test_gpt5_p4_memory.py:592\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/tests/unit/test_gpt5_p4_memory.py:592: PytestUnknownMarkWarning: Unknown pytest.mark.gpt5 - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.gpt5\n\ntests/unit/test_gpt5_p4_memory.py:593\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/tests/unit/test_gpt5_p4_memory.py:593: PytestUnknownMarkWarning: Unknown pytest.mark.memory - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.memory\n\ntests/unit/test_gpt5_p4_memory.py:674\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/tests/unit/test_gpt5_p4_memory.py:674: PytestUnknownMarkWarning: Unknown pytest.mark.unit - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.unit\n\ntests/unit/test_gpt5_p4_memory.py:675\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/tests/unit/test_gpt5_p4_memory.py:675: PytestUnknownMarkWarning: Unknown pytest.mark.gpt5 - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.gpt5\n\ntests/unit/test_gpt5_p4_memory.py:676\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/tests/unit/test_gpt5_p4_memory.py:676: PytestUnknownMarkWarning: Unknown pytest.mark.memory - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.memory\n\ntests/unit/test_gpt5_p5_security.py:23\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/tests/unit/test_gpt5_p5_security.py:23: PytestUnknownMarkWarning: Unknown pytest.mark.unit - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.unit\n\ntests/unit/test_gpt5_p5_security.py:24\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/tests/unit/test_gpt5_p5_security.py:24: PytestUnknownMarkWarning: Unknown pytest.mark.gpt5 - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.gpt5\n\ntests/unit/test_gpt5_p5_security.py:25\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/tests/unit/test_gpt5_p5_security.py:25: PytestUnknownMarkWarning: Unknown pytest.mark.security - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.security\n\ntests/unit/test_gpt5_p5_security.py:631\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/tests/unit/test_gpt5_p5_security.py:631: PytestUnknownMarkWarning: Unknown pytest.mark.unit - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.unit\n\ntests/unit/test_gpt5_p5_security.py:632\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/tests/unit/test_gpt5_p5_security.py:632: PytestUnknownMarkWarning: Unknown pytest.mark.gpt5 - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.gpt5\n\ntests/unit/test_gpt5_p5_security.py:633\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/tests/unit/test_gpt5_p5_security.py:633: PytestUnknownMarkWarning: Unknown pytest.mark.security - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.security\n\ntests/unit/test_gpt5_p5_security.py:677\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/tests/unit/test_gpt5_p5_security.py:677: PytestUnknownMarkWarning: Unknown pytest.mark.unit - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.unit\n\ntests/unit/test_gpt5_p5_security.py:678\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/tests/unit/test_gpt5_p5_security.py:678: PytestUnknownMarkWarning: Unknown pytest.mark.gpt5 - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.gpt5\n\ntests/unit/test_gpt5_p5_security.py:679\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/tests/unit/test_gpt5_p5_security.py:679: PytestUnknownMarkWarning: Unknown pytest.mark.security - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.security\n\ntests/unit/test_gpt5_p5_security.py:700\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/tests/unit/test_gpt5_p5_security.py:700: PytestUnknownMarkWarning: Unknown pytest.mark.unit - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.unit\n\ntests/unit/test_gpt5_p5_security.py:701\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/tests/unit/test_gpt5_p5_security.py:701: PytestUnknownMarkWarning: Unknown pytest.mark.gpt5 - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.gpt5\n\ntests/unit/test_gpt5_p5_security.py:702\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/tests/unit/test_gpt5_p5_security.py:702: PytestUnknownMarkWarning: Unknown pytest.mark.security - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.security\n\ntests/conftest.py:506\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/tests/conftest.py:506: PytestUnknownMarkWarning: Unknown pytest.mark.unit - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    item.add_marker(pytest.mark.unit)\n\ntests/unit/test_gpt5_p10_causal.py::TestCausalAnalyticsEngine::test_causal_analytics_initialization\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/venv/lib/python3.9/site-packages/pytest_asyncio/plugin.py:769: DeprecationWarning: The event_loop fixture provided by pytest-asyncio has been redefined in\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/tests/conftest.py:49\n  Replacing the event_loop fixture with a custom implementation is deprecated\n  and will lead to errors in the future.\n  If you want to request an asyncio event loop with a scope other than function\n  scope, use the \"scope\" argument to the asyncio mark when marking the tests.\n  If you want to return different types of event loops, use the event_loop_policy\n  fixture.\n  \n    warnings.warn(\n\ntests/unit/test_gpt5_p10_causal.py::TestCausalInferenceMethods::test_causal_methods_from_test_data\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/venv/lib/python3.9/site-packages/threadpoolctl.py:1226: RuntimeWarning: \n  Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n  the same time. Both libraries are known to be incompatible and this\n  can cause random crashes or deadlocks on Linux when loaded in the\n  same Python program.\n  Using threadpoolctl may cause crashes or deadlocks. For more\n  information and possible workarounds, please see\n      https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n  \n    warnings.warn(msg, RuntimeWarning)\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n\n---------- coverage: platform darwin, python 3.9.6-final-0 -----------\nName                                                 Stmts   Miss  Cover   Missing\n----------------------------------------------------------------------------------\napi/__init__.py                                          2      0   100%\napi/auth.py                                            196    196     0%   5-417\napi/main.py                                            276    182    34%   69-72, 75-78, 81-91, 103-123, 148, 162-195, 210-224, 230-262, 277-283, 289-295, 301-308, 315-336, 343-358, 364-373, 385-390, 401-415, 422-432, 438-449, 464-510, 517-545, 552-565, 580-588, 594-600, 604-605\napi/middleware.py                                        2      2     0%   9-19\napi/routes.py                                            2      2     0%   10-23\napi/websocket.py                                         2      2     0%   9-18\ncore/__init__.py                                         7      0   100%\ncore/__main__.py                                        63     63     0%   6-156\ncore/agents/__init__.py                                 10      0   100%\ncore/agents/analyzer_agent.py                          415    349    16%   32-60, 64, 76-93, 97-132, 144-177, 195-248, 259-293, 308-357, 368-402, 419-429, 433-464, 468-478, 482-491, 495-514, 518-533, 537-543, 547, 559-577, 581-604, 608-622, 626-641, 645-650, 654-661, 665-675, 679-692, 696, 700-712, 716-725, 729-734, 738-745, 749-764, 768-779, 783-785, 793, 802-815, 819-828, 832, 849, 874, 890-893, 902-905, 913, 921-933, 937-953, 957-965, 969-981, 985, 993\ncore/agents/architect_agent.py                         236    174    26%   33-58, 62, 112, 124-139, 143-177, 186-238, 246-280, 291-326, 336-366, 375, 387-398, 402, 427, 447, 457-470, 478, 488-496, 500, 510, 528, 537, 547-555, 559, 565-570, 574-581, 585, 593-605, 609, 613-616, 630, 637, 644, 651-656, 660, 668-673, 677, 685, 692, 700, 708-712, 716, 726, 735\ncore/agents/base_agent.py                              217    153    29%   66-102, 107, 112, 117, 125-133, 140, 144-171, 179-242, 246-248, 252-266, 270, 278-299, 303-339, 343-384, 388-394, 401-412, 417, 421-432, 436, 451-461\ncore/agents/cli_agents/__init__.py                       4      4     0%   5-9\ncore/agents/cli_agents/aider_codex_agent.py            108    108     0%   5-303\ncore/agents/cli_agents/claude_code_agent.py            172    172     0%   5-461\ncore/agents/cli_agents/gemini_cli_agent.py             146    146     0%   5-444\ncore/agents/coder_agent.py                             259    219    15%   27-65, 72-111, 120-143, 147-171, 175-200, 204-229, 233-257, 261-278, 286-369, 373-392, 397-427, 437-462, 473-499, 509-527, 536-568, 579-587, 591-595, 599-611, 615-618, 630, 639-648, 652-680, 684, 694\ncore/agents/debugger_agent.py                          344    285    17%   31-69, 76-110, 114, 154, 183-198, 202-241, 253-351, 363-390, 398-440, 448-499, 507-514, 518-529, 533-546, 550-567, 571-595, 599-620, 624-633, 638-652, 657-678, 683, 688, 692-696, 700-702, 706-707, 715-722, 727, 732, 736, 744, 748, 752-764, 768-775, 779, 783-785, 789, 793-800, 804-813, 818, 822, 826, 830-840, 844, 853\ncore/agents/example_skills.py                          313    251    20%   26-33, 37-67, 78-79, 89-90, 106-107, 122, 137-138, 142-143, 147-148, 152-177, 181, 191, 205-212, 216-250, 261-270, 274-283, 287-303, 307, 336, 357, 366, 379-386, 390-422, 433-434, 442-448, 452, 456, 460-467, 471-479, 483, 492, 505-512, 516-559, 570-581, 585-619, 623-647, 651-656, 660, 670, 683-690, 694-735, 746-784, 788-822, 826-845, 849-861, 865, 874\ncore/agents/gpt5_direct_client.py                       62     62     0%   6-252\ncore/agents/modular_skills.py                          326    224    31%   85-95, 100, 105, 110, 114-135, 139-145, 149-167, 173, 200-207, 211-213, 217-230, 234-276, 287-305, 309-327, 331-342, 346, 350, 365-377, 381-390, 394, 398-399, 403-407, 411-415, 420-444, 448-476, 480-492, 506-528, 533-551, 558-577, 582-591, 597-607\ncore/agents/tester_agent.py                            223    184    17%   31-69, 76-110, 118, 137, 157, 185-200, 207-273, 282-316, 326-350, 361-383, 395-420, 429-462, 466-492, 496-507, 511-513, 517, 521-543, 548, 557-567, 571, 580\ncore/agents/ui_refiner_agent.py                        305    234    23%   31-56, 60, 72, 96-111, 115-150, 159-189, 199-237, 248-282, 293-336, 347-368, 372-390, 394-413, 417-426, 430-439, 443-454, 458, 467-477, 481-492, 496-501, 505-521, 525, 534-552, 556-567, 571-586, 590-600, 604-614, 618, 634-641, 645-650, 654, 662, 670, 677, 684-693, 697, 705, 709, 717, 724, 731, 738, 745, 752, 762, 771, 779, 787, 791, 795-804, 808, 812, 817, 821, 829\ncore/causal_analytics/__init__.py                        2      0   100%\ncore/causal_analytics/causal_graph_analytics.py        569    392    31%   175-180, 184-186, 190-195, 199-202, 206, 210, 214, 218, 222-225, 229, 233-241, 245, 249, 257-297, 303-341, 347, 352-393, 406-431, 448-455, 464-503, 522-589, 608-665, 681-689, 693-772, 776-797, 808-859, 866-892, 902-929, 936-953, 962-1014, 1023-1076, 1080-1106, 1110-1121, 1125-1140, 1149-1173, 1177-1194\ncore/communication/__init__.py                           2      2     0%   8-16\ncore/communication/agent_message_bus.py                241    241     0%   9-540\ncore/deployment/__init__.py                              2      0   100%\ncore/deployment/deployment_orchestrator.py             512    355    31%   192-242, 247-372, 376-391, 395-497, 501-537, 541-600, 607-624, 628-634, 638-664, 668-690, 698-747, 755-774, 779, 783-803, 807-856, 863-882, 886-904, 908-913, 917-922, 926-931, 938-983, 987-1007, 1011-1042, 1046, 1050, 1064, 1078, 1093-1103, 1107-1125\ncore/ethics/__init__.py                                  2      2     0%   6-19\ncore/evaluation/__init__.py                              2      2     0%   8-15\ncore/evaluation/iteration_quality_framework.py         206    206     0%   8-547\ncore/governance/__init__.py                              2      2     0%   8-10\ncore/governance/meta_governor.py                       164    164     0%   9-366\ncore/knowledge/__init__.py                              12      2    83%   34-36\ncore/knowledge/code_embedder.py                        166    137    17%   51-54, 93-120, 130-148, 164-165, 185-242, 250-325, 329-333, 341-365, 369-376, 381-382, 386-393, 402-410\ncore/knowledge/codebase_indexer.py                     215    168    22%   34, 101-108, 112-137, 149-178, 190-208, 214-251, 257-298, 309-365, 377-378, 390-394, 398-401, 405-422, 426-431, 435-442, 446, 450-455\ncore/knowledge/knowledge_graph_manager.py              526    374    29%   169-171, 175-176, 180-198, 202-213, 217-243, 247-279, 297-340, 344-397, 402-430, 434-462, 466-505, 509-555, 559-586, 590-591, 611-612, 632, 636-639, 643, 647-661, 665-679, 683-721, 731-769, 781, 789-823, 827-925, 929-1030, 1034-1060, 1064-1133, 1137-1152, 1171-1215, 1219-1275\ncore/knowledge/rag_retriever.py                        146    118    19%   78-94, 105-140, 157-226, 257-319, 343-396, 415-434, 443-449\ncore/knowledge/vector_store.py                         114     94    18%   40-43, 80-101, 105-123, 135-158, 182-222, 241-284, 288-300, 311-339, 347-358\ncore/learning/__init__.py                                2      0   100%\ncore/learning/pattern_recognition.py                   229    177    23%   46-69, 73-89, 93-107, 112-135, 140-167, 172-198, 203-217, 221-227, 244-270, 274-310, 315-340, 344, 349-357, 362-368, 376-379, 393-399, 403-413, 417-429, 433-435, 439-459, 463-469, 473-474\ncore/learning/reinforcement_learning_engine.py         262    262     0%   9-565\ncore/memory/__init__.py                                  5      0   100%\ncore/memory/cache_eviction.py                          182    144    21%   42-43, 47-50, 54, 58, 79-108, 125-169, 178-205, 209-212, 216-232, 236-286, 290-317, 322-340, 344, 348-354, 364-369\ncore/memory/error_knowledge_graph.py                   189    140    26%   32, 60, 80-90, 94-153, 157-205, 217-273, 287-361, 365-382, 386-400, 405-416, 421-426, 436-482, 486-496, 500-535, 539-564\ncore/memory/memory_orchestrator.py                     300    228    24%   91-116, 141-185, 210-266, 295-347, 360-403, 422-467, 480-519, 523-553, 562-590, 599-617, 621-646, 650-663, 667-679, 683-710, 714-728, 732-750, 754-765, 770-780\ncore/memory/project_ledger.py                          150    113    25%   31, 52-62, 66-122, 126-141, 163-229, 233-245, 249-278, 282-285, 289-315, 328-355, 367-381, 385-420, 430-445, 449-472, 476-477\ncore/memory/vector_memory.py                           251    212    16%   32-33, 40-82, 86-89, 96-99, 103-105, 116-156, 168-211, 221-244, 253-314, 319-340, 345-370, 375-394, 413-453, 472-508, 523-546, 551-563\ncore/memory_pyramid/hierarchical_memory_pyramid.py     401    312    22%   65, 84, 131-181, 185-196, 200-210, 216-255, 260-281, 287-325, 330-353, 358-379, 384-406, 411-457, 464-506, 512-519, 524-557, 562-569, 574-579, 585-602, 607-640, 645-657, 662-678, 683-698, 703-727, 736-744, 749-768, 773-779, 784-788, 794-799, 804-835, 842-875, 883-939\ncore/observability/__init__.py                           5      0   100%\ncore/observability/agent_tracer.py                     225    180    20%   37-38, 41, 61-68, 72-93, 97-139, 148-165, 169-204, 213-224, 231, 235-262, 267-325, 334-343, 352-353, 357-358, 362-364, 374-410, 432-464, 478-523\ncore/observability/dashboard_collector.py              266    195    27%   51, 88, 105-128, 132-139, 143-149, 153-154, 158-161, 169-183, 187-239, 243-250, 260-300, 310-322, 331-348, 356-370, 378-395, 400-406, 410-443, 455-472, 476-493, 499-503, 507-550, 554, 586-587, 591-611, 618-630, 637-649\ncore/observability/system_monitor.py                   160    116    28%   37, 61-90, 94-104, 108-114, 118-133, 138-160, 180-217, 221-255, 259-284, 288-296, 303-306, 318-321, 325-332, 336-349, 368-375, 379-393, 400-404\ncore/observability/telemetry_engine.py                 217    129    41%   43, 67-70, 74-76, 80, 84-89, 92, 117, 134-156, 160-169, 173-177, 181-185, 189-191, 198-216, 221, 226, 231, 237-252, 256-261, 266, 272-286, 289, 292, 295, 298, 301, 307-323, 328-335, 339-345, 350-359, 363-364, 378-384, 393-399, 410-412, 417-418\ncore/optimization/__init__.py                            2      2     0%   6-16\ncore/optimization/adaptive_prompt_optimizer.py         726    726     0%   6-1799\ncore/orchestrator/__init__.py                            5      0   100%\ncore/orchestrator/checkpoint_manager.py                142    104    27%   37-46, 50-56, 60, 90-123, 128-153, 157-177, 182-202, 206-209, 213-216, 220-226, 231-250, 257-259, 271-279, 283-307\ncore/orchestrator/continuous_director.py               626    519    17%   76, 105, 118, 138-185, 189-241, 245-268, 272-305, 309-340, 344-368, 382-392, 401-417, 421-494, 498-519, 524-540, 546-556, 560-582, 586-602, 606-620, 625-656, 660-719, 728-817, 821-843, 847-878, 884-926, 930-955, 964-974, 978-991, 995-1008, 1014-1028, 1034-1035, 1039-1040, 1044-1045, 1055-1090, 1098-1166, 1169-1179, 1183-1217, 1221-1230, 1234-1243, 1247-1260, 1264-1273, 1277-1286, 1290-1306, 1316-1333, 1342-1360, 1368-1400\ncore/orchestrator/guardrails.py                        129     91    29%   64-78, 85, 134, 192-263, 282-298, 316-345, 349-353, 378-384, 401-414, 431-437, 441, 452-455, 474-477, 490-511\ncore/orchestrator/milestone_tracker.py                 144    100    31%   43, 65-72, 76-86, 90-112, 116-128, 139-156, 160-185, 189-200, 206, 210-234, 238-249, 253-255, 259-269, 287-326\ncore/orchestrator/progress_analyzer.py                 174    138    21%   36-46, 50-71, 88-118, 122-140, 150-181, 185-207, 211-233, 237-256, 270-283, 293-303, 307-335, 339-371, 375-396\ncore/orchestrator/task_validator.py                    185    141    24%   63-67, 73-153, 165-168, 185-251, 266-281, 292-324, 328-346, 356-371, 378-394, 404-417, 424-447, 458, 462-480, 488-510\ncore/orchestrator/tri_agent_sdlc.py                    339    339     0%   11-895\ncore/reasoning/__init__.py                               2      2     0%   6-15\ncore/reasoning/cross_agent_coordinator.py              396    396     0%   6-939\ncore/resilience/__init__.py                              4      4     0%   18-36\ncore/resilience/circuit_breaker.py                     134    134     0%   30-484\ncore/resilience/retry_strategy.py                       93     93     0%   29-359\ncore/resilience/task_ledger.py                         163    163     0%   33-579\ncore/review/__init__.py                                  2      2     0%   8-17\ncore/review/human_review_gateway.py                    252    252     0%   9-577\ncore/routing/__init__.py                                 5      5     0%   19-24\ncore/routing/capability_matrix.py                       39     39     0%   7-142\ncore/routing/load_tracker.py                            71     71     0%   7-178\ncore/routing/task_fitness_router.py                     76     76     0%   10-272\ncore/routing/win_rate_tracker.py                        73     73     0%   7-203\ncore/security/__init__.py                                2      0   100%\ncore/security/security_compliance_scanner.py           288    151    48%   362-443, 447-484, 489-521, 536-569, 575-633, 643-652, 656-659, 666-708, 712-731, 735-744, 750-773, 777, 786-814\ncore/self_healing/__init__.py                            2      0   100%\ncore/self_healing/self_healing_orchestrator.py         518    371    28%   177-221, 225-226, 235, 312, 364-386, 390-409, 413-428, 432-445, 449-462, 466-557, 569-600, 604-616, 629-648, 652-661, 665-746, 753-765, 769-788, 793-824, 828-841, 845-877, 881-895, 899-935, 939-977, 981-988, 992-1003, 1025, 1029\ncore/utils/__init__.py                                   2      0   100%\ncore/utils/audit_logger.py                              74     48    35%   70-95, 114-133, 154-165, 173, 193, 221-238, 246, 261-265, 271-275\ncore/utils/filesystem.py                                93     82    12%   27-80, 97-122, 139-157, 170, 183-202, 215-224\ncore/utils/pii_scanner.py                               93     66    29%   84-89, 106-141, 157-180, 190-204, 217-231, 235-249, 253-259, 267, 281-287, 300-301\ncore/utils/retry_handler.py                             84     84     0%   10-263\n----------------------------------------------------------------------------------\nTOTAL                                                14355  11751    18%\n\n=========================== short test summary info ============================\nFAILED tests/unit/test_gpt5_p10_causal.py::TestCausalAnalyticsEngine::test_causal_discovery\nFAILED tests/unit/test_gpt5_p10_causal.py::TestCausalAnalyticsEngine::test_large_scale_causal_analysis\nFAILED tests/unit/test_gpt5_p4_memory.py::TestHierarchicalMemoryPyramid::test_initialization\nFAILED tests/unit/test_gpt5_p4_memory.py::TestHierarchicalMemoryPyramid::test_store_memory_working_tier\nFAILED tests/unit/test_gpt5_p4_memory.py::TestHierarchicalMemoryPyramid::test_store_multiple_memories\nFAILED tests/unit/test_gpt5_p4_memory.py::TestHierarchicalMemoryPyramid::test_retrieve_memory_by_id\nFAILED tests/unit/test_gpt5_p4_memory.py::TestHierarchicalMemoryPyramid::test_search_memories_by_content\nFAILED tests/unit/test_gpt5_p4_memory.py::TestHierarchicalMemoryPyramid::test_search_memories_by_type\nFAILED tests/unit/test_gpt5_p4_memory.py::TestHierarchicalMemoryPyramid::test_memory_consolidation_by_count\nFAILED tests/unit/test_gpt5_p4_memory.py::TestHierarchicalMemoryPyramid::test_memory_consolidation_by_time\nFAILED tests/unit/test_gpt5_p4_memory.py::TestHierarchicalMemoryPyramid::test_memory_compression\nFAILED tests/unit/test_gpt5_p4_memory.py::TestHierarchicalMemoryPyramid::test_memory_importance_scoring\nFAILED tests/unit/test_gpt5_p4_memory.py::TestHierarchicalMemoryPyramid::test_memory_relationships\nFAILED tests/unit/test_gpt5_p4_memory.py::TestHierarchicalMemoryPyramid::test_memory_statistics\nFAILED tests/unit/test_gpt5_p4_memory.py::TestHierarchicalMemoryPyramid::test_memory_cleanup\nFAILED tests/unit/test_gpt5_p4_memory.py::TestHierarchicalMemoryPyramid::test_memory_export_import\nFAILED tests/unit/test_gpt5_p4_memory.py::TestHierarchicalMemoryPyramid::test_concurrent_memory_operations\nFAILED tests/unit/test_gpt5_p4_memory.py::TestHierarchicalMemoryPyramid::test_memory_tier_promotion\nFAILED tests/unit/test_gpt5_p4_memory.py::TestHierarchicalMemoryPyramid::test_memory_pyramid_performance\nFAILED tests/unit/test_gpt5_p4_memory.py::TestMemoryNode::test_memory_node_creation\nFAILED tests/unit/test_gpt5_p4_memory.py::TestMemoryNode::test_memory_node_serialization\nFAILED tests/unit/test_gpt5_p4_memory.py::TestMemoryNode::test_memory_node_update_access\nFAILED tests/unit/test_gpt5_p4_memory.py::TestMemoryNode::test_memory_node_importance_decay\nFAILED tests/unit/test_gpt5_p4_memory.py::TestMemoryTierEnums::test_memory_type_enum\nFAILED tests/unit/test_gpt5_p5_security.py::TestSecurityComplianceScanner::test_scanner_initialization\nFAILED tests/unit/test_gpt5_p5_security.py::TestSecurityComplianceScanner::test_sql_injection_detection\nFAILED tests/unit/test_gpt5_p5_security.py::TestSecurityComplianceScanner::test_xss_vulnerability_detection\nFAILED tests/unit/test_gpt5_p5_security.py::TestSecurityComplianceScanner::test_hardcoded_secrets_detection\nFAILED tests/unit/test_gpt5_p5_security.py::TestSecurityComplianceScanner::test_insecure_crypto_detection\nFAILED tests/unit/test_gpt5_p5_security.py::TestSecurityComplianceScanner::test_path_traversal_detection\nFAILED tests/unit/test_gpt5_p5_security.py::TestSecurityComplianceScanner::test_scan_file\nFAILED tests/unit/test_gpt5_p5_security.py::TestSecurityComplianceScanner::test_scan_directory\nFAILED tests/unit/test_gpt5_p5_security.py::TestSecurityComplianceScanner::test_owasp_compliance_check\nFAILED tests/unit/test_gpt5_p5_security.py::TestSecurityComplianceScanner::test_gdpr_compliance_check\nFAILED tests/unit/test_gpt5_p5_security.py::TestSecurityComplianceScanner::test_pci_dss_compliance_check\nFAILED tests/unit/test_gpt5_p5_security.py::TestSecurityComplianceScanner::test_risk_assessment\nFAILED tests/unit/test_gpt5_p5_security.py::TestSecurityComplianceScanner::test_security_report_generation\nFAILED tests/unit/test_gpt5_p5_security.py::TestSecurityComplianceScanner::test_false_positive_handling\nFAILED tests/unit/test_gpt5_p5_security.py::TestSecurityComplianceScanner::test_vulnerability_pattern_updates\nFAILED tests/unit/test_gpt5_p5_security.py::TestSecurityComplianceScanner::test_scan_performance\nFAILED tests/unit/test_gpt5_p5_security.py::TestSecurityComplianceScanner::test_concurrent_scanning\nFAILED tests/unit/test_gpt5_p5_security.py::TestSecurityVulnerability::test_security_issue_creation\nFAILED tests/unit/test_gpt5_p5_security.py::TestSecurityVulnerability::test_security_issue_serialization\nFAILED tests/unit/test_gpt5_p5_security.py::TestSecurityLevelEnum::test_risk_level_values\nFAILED tests/unit/test_gpt5_p5_security.py::TestVulnerabilityTypeEnum::test_vulnerability_types_exist\nFAILED tests/unit/test_gpt5_p5_security.py::TestVulnerabilityTypeEnum::test_vulnerability_type_values\nFAILED tests/unit/test_gpt5_p6_healing.py::TestSelfHealingOrchestrator::test_repair_action_execution_failure\nFAILED tests/unit/test_gpt5_p6_healing.py::TestSelfHealingOrchestrator::test_repair_action_rollback_capability\nFAILED tests/unit/test_gpt5_p6_healing.py::TestSystemResilienceValidation::test_chaos_engineering_network_partition\nFAILED tests/unit/test_gpt5_p7_knowledge.py::TestKnowledgeGraphManager::test_entity_embedding_generation\nFAILED tests/unit/test_gpt5_p7_knowledge.py::TestKnowledgeGraphManager::test_multi_depth_relationship_traversal\nFAILED tests/unit/test_gpt5_p7_knowledge.py::TestKnowledgeGraphManager::test_large_scale_graph_performance\nFAILED tests/unit/test_gpt5_p7_knowledge.py::TestKnowledgeTransferAndLearning::test_cross_project_pattern_recognition\nFAILED tests/unit/test_gpt5_p7_knowledge.py::TestKnowledgeTransferAndLearning::test_solution_pattern_generalization\nFAILED tests/unit/test_gpt5_p9_deployment.py::TestDeploymentOrchestrator::test_deployment_config_validation\nFAILED tests/unit/test_gpt5_p9_deployment.py::TestDeploymentOrchestrator::test_deployment_creation\nFAILED tests/unit/test_gpt5_p9_deployment.py::TestDeploymentOrchestrator::test_deployment_creation_with_invalid_config\nFAILED tests/unit/test_gpt5_p9_deployment.py::TestDeploymentOrchestrator::test_deployment_pipeline_execution_success\nFAILED tests/unit/test_gpt5_p9_deployment.py::TestDeploymentOrchestrator::test_quality_gates_integration\nFAILED tests/unit/test_gpt5_p9_deployment.py::TestDeploymentOrchestrator::test_deployment_rollback_on_failure\nFAILED tests/unit/test_gpt5_p9_deployment.py::TestDeploymentOrchestrator::test_deployment_cancellation\nFAILED tests/unit/test_gpt5_p9_deployment.py::TestDeploymentOrchestrator::test_deployment_scaling\nFAILED tests/unit/test_gpt5_p9_deployment.py::TestDeploymentOrchestrator::test_deployment_metrics_collection\nFAILED tests/unit/test_gpt5_p9_deployment.py::TestDeploymentOrchestrator::test_deployment_status_retrieval\nFAILED tests/unit/test_gpt5_p9_deployment.py::TestDeploymentOrchestrator::test_deployment_with_different_strategies\nFAILED tests/unit/test_gpt5_p9_deployment.py::TestDeploymentOrchestrator::test_concurrent_deployments\nFAILED tests/unit/test_gpt5_p9_deployment.py::TestDeploymentOrchestrator::test_deployment_timeout_handling\nFAILED tests/unit/test_gpt5_p9_deployment.py::TestDeploymentOrchestrator::test_post_deployment_validation\nFAILED tests/unit/test_gpt5_p9_deployment.py::TestDeploymentPipelineIntegration::test_pipeline_stages_from_test_data\nFAILED tests/unit/test_gpt5_p9_deployment.py::TestDeploymentPipelineIntegration::test_quality_gates_from_test_data\nFAILED tests/unit/test_gpt5_p9_deployment.py::TestDeploymentPipelineIntegration::test_deployment_strategies_from_test_data\nFAILED tests/unit/test_gpt5_p9_deployment.py::TestDeploymentPipelineIntegration::test_multi_environment_deployment_workflow\n============ 72 failed, 79 passed, 65 warnings in 832.50s (0:13:52) ============\n",
      "stderr": "/Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n  warnings.warn(\n",
      "command": "/Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/venv/bin/python -m pytest tests/unit/ -m unit -v --cov=core --cov=api --cov-report=term-missing",
      "summary": "============ 72 failed, 79 passed, 65 warnings in 832.50s (0:13:52) ============"
    },
    "integration": {
      "category": "integration",
      "status": "FAILED",
      "duration": 22.240215063095093,
      "returncode": 2,
      "stdout": "============================= test session starts ==============================\nplatform darwin -- Python 3.9.6, pytest-8.1.1, pluggy-1.6.0 -- /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/venv/bin/python\ncachedir: .pytest_cache\nrootdir: /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder\nconfigfile: pytest.ini\nplugins: asyncio-0.23.5, anyio-4.12.0, langsmith-0.4.37, cov-4.1.0\nasyncio: mode=strict\ncollecting ... collected 0 items / 1 error\n\n==================================== ERRORS ====================================\n_____ ERROR collecting tests/integration/test_multi_agent_coordination.py ______\nImportError while importing test module '/Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/tests/integration/test_multi_agent_coordination.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/importlib/__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests/integration/test_multi_agent_coordination.py:29: in <module>\n    from tests.fixtures.agent_fixtures import (\nE   ImportError: cannot import name 'MockCoderAgent' from 'tests.fixtures.agent_fixtures' (/Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/tests/fixtures/agent_fixtures.py)\n------------------------------- Captured stdout --------------------------------\n\u001b[32m2025-11-29 06:18:03\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mconfig.logging_config\u001b[0m:\u001b[36msetup_logging\u001b[0m:\u001b[36m100\u001b[0m - \u001b[1mLogging configured: level=INFO, file_logging=True\u001b[0m\n------------------------------- Captured stderr --------------------------------\n\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.0.2 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\nTraceback (most recent call last):  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"/Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/venv/lib/python3.9/site-packages/pytest/__main__.py\", line 7, in <module>\n    raise SystemExit(pytest.console_main())\n  File \"/Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/venv/lib/python3.9/site-packages/_pytest/config/__init__.py\", line 197, in console_main\n    code = main()\n  File \"/Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/venv/lib/python3.9/site-packages/_pytest/config/__init__.py\", line 155, in main\n    config = _prepareconfig(args, plugins)\n  File \"/Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/venv/lib/python3.9/site-packages/_pytest/config/__init__.py\", line 337, in _prepareconfig\n    config = pluginmanager.hook.pytest_cmdline_parse(\n  File \"/Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/venv/lib/python3.9/site-packages/pluggy/_hooks.py\", line 512, in __call__\n    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n  File \"/Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/venv/lib/python3.9/site-packages/pluggy/_manager.py\", line 120, in _hookexec\n    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n  File \"/Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/venv/lib/python3.9/site-packages/pluggy/_callers.py\", line 121, in _multicall\n    res = hook_impl.function(*args)\n  File \"/Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/venv/lib/python3.9/site-packages/_pytest/config/__init__.py\", line 1143, in pytest_cmdline_parse\n    self.parse(args)\n  File \"/Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/venv/lib/python3.9/site-packages/_pytest/config/__init__.py\", line 1492, in parse\n    self._preparse(args, addopts=addopts)\n  File \"/Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/venv/lib/python3.9/site-packages/_pytest/config/__init__.py\", line 1396, in _preparse\n    self.hook.pytest_load_initial_conftests(\n  File \"/Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/venv/lib/python3.9/site-packages/pluggy/_hooks.py\", line 512, in __call__\n    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n  File \"/Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/venv/lib/python3.9/site-packages/pluggy/_manager.py\", line 120, in _hookexec\n    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n  File \"/Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/venv/lib/python3.9/site-packages/pluggy/_callers.py\", line 121, in _multicall\n    res = hook_impl.function(*args)\n  File \"/Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/venv/lib/python3.9/site-packages/_pytest/config/__init__.py\", line 1221, in pytest_load_initial_conftests\n    self.pluginmanager._set_initial_conftests(\n  File \"/Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/venv/lib/python3.9/site-packages/_pytest/config/__init__.py\", line 579, in _set_initial_conftests\n    self._try_load_conftest(\n  File \"/Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/venv/lib/python3.9/site-packages/_pytest/config/__init__.py\", line 617, in _try_load_conftest\n    self._loadconftestmodules(\n  File \"/Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/venv/lib/python3.9/site-packages/_pytest/config/__init__.py\", line 657, in _loadconftestmodules\n    mod = self._importconftest(\n  File \"/Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/venv/lib/python3.9/site-packages/_pytest/config/__init__.py\", line 708, in _importconftest\n    mod = import_path(\n  File \"/Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/venv/lib/python3.9/site-packages/_pytest/pathlib.py\", line 584, in import_path\n    importlib.import_module(module_name)\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/importlib/__init__.py\", line 127, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"/Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/venv/lib/python3.9/site-packages/_pytest/assertion/rewrite.py\", line 178, in exec_module\n    exec(co, module.__dict__)\n  File \"/Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/tests/conftest.py\", line 17, in <module>\n    from core.orchestrator.continuous_director import ContinuousDirector\n  File \"/Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/core/__init__.py\", line 10, in <module>\n    from . import agents\n  File \"/Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/core/agents/__init__.py\", line 8, in <module>\n    from .coder_agent import CoderAgent\n  File \"/Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/core/agents/coder_agent.py\", line 13, in <module>\n    from langchain_openai import ChatOpenAI\n  File \"/Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/venv/lib/python3.9/site-packages/langchain_openai/__init__.py\", line 3, in <module>\n    from langchain_openai.chat_models import AzureChatOpenAI, ChatOpenAI\n  File \"/Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/venv/lib/python3.9/site-packages/langchain_openai/chat_models/__init__.py\", line 3, in <module>\n    from langchain_openai.chat_models.azure import AzureChatOpenAI\n  File \"/Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/venv/lib/python3.9/site-packages/langchain_openai/chat_models/azure.py\", line 11, in <module>\n    from langchain_core.language_models import LanguageModelInput\n  File \"/Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/venv/lib/python3.9/site-packages/langchain_core/language_models/__init__.py\", line 112, in __getattr__\n    result = import_attr(attr_name, module_name, __spec__.parent)\n  File \"/Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/venv/lib/python3.9/site-packages/langchain_core/_import_utils.py\", line 36, in import_attr\n    module = import_module(f\".{module_name}\", package=package)\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/importlib/__init__.py\", line 127, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"/Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/venv/lib/python3.9/site-packages/langchain_core/language_models/base.py\", line 44, in <module>\n    from transformers import GPT2TokenizerFast  # type: ignore[import-not-found]\n  File \"/Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/venv/lib/python3.9/site-packages/transformers/__init__.py\", line 27, in <module>\n    from . import dependency_versions_check\n  File \"/Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/venv/lib/python3.9/site-packages/transformers/dependency_versions_check.py\", line 16, in <module>\n    from .utils.versions import require_version, require_version_core\n  File \"/Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/venv/lib/python3.9/site-packages/transformers/utils/__init__.py\", line 24, in <module>\n    from .auto_docstring import (\n  File \"/Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/venv/lib/python3.9/site-packages/transformers/utils/auto_docstring.py\", line 30, in <module>\n    from .generic import ModelOutput\n  File \"/Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/venv/lib/python3.9/site-packages/transformers/utils/generic.py\", line 51, in <module>\n    import torch\n  File \"/Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n    from .functional import *  # noqa: F403\n  File \"/Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n    import torch.nn.functional as F\n  File \"/Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n    from .modules import *  # noqa: F403\n  File \"/Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n    from .transformer import TransformerEncoder, TransformerDecoder, \\\n  File \"/Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\ntree-sitter not available; will use Python ast fallback\n=============================== warnings summary ===============================\nvenv/lib/python3.9/site-packages/jupyter_client/connect.py:22\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/venv/lib/python3.9/site-packages/jupyter_client/connect.py:22: DeprecationWarning: Jupyter is migrating its paths to use standard platformdirs\n  given by the platformdirs library.  To remove this warning and\n  see the appropriate new directories, set the environment variable\n  `JUPYTER_PLATFORM_DIRS=1` and then run `jupyter --paths`.\n  The use of platformdirs will be the default in `jupyter_core` v6\n    from jupyter_core.paths import jupyter_data_dir, jupyter_runtime_dir, secure_write\n\nvenv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n\nconfig/settings.py:19\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:19: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    DEBUG: bool = Field(default=False, env=\"DEBUG\")\n\nconfig/settings.py:22\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:22: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    API_HOST: str = Field(default=\"0.0.0.0\", env=\"API_HOST\")\n\nconfig/settings.py:23\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:23: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    API_PORT: int = Field(default=8000, env=\"API_PORT\")\n\nconfig/settings.py:24\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:24: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    API_WORKERS: int = Field(default=4, env=\"API_WORKERS\")\n\nconfig/settings.py:25\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:25: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    CORS_ORIGINS: List[str] = Field(\n\nconfig/settings.py:31\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:31: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    DATABASE_URL: str = Field(\n\nconfig/settings.py:35\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:35: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    DATABASE_POOL_SIZE: int = Field(default=20, env=\"DATABASE_POOL_SIZE\")\n\nconfig/settings.py:36\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:36: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    DATABASE_MAX_OVERFLOW: int = Field(default=10, env=\"DATABASE_MAX_OVERFLOW\")\n\nconfig/settings.py:39\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:39: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    REDIS_URL: str = Field(default=\"redis://localhost:6379/0\", env=\"REDIS_URL\")\n\nconfig/settings.py:40\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:40: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    REDIS_MAX_CONNECTIONS: int = Field(default=50, env=\"REDIS_MAX_CONNECTIONS\")\n\nconfig/settings.py:42\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:42: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    @validator(\"DATABASE_URL\", pre=True, always=True)\n\nconfig/settings.py:55\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:55: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    CHROMADB_HOST: str = Field(default=\"localhost\", env=\"CHROMADB_HOST\")\n\nconfig/settings.py:56\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:56: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    CHROMADB_PORT: int = Field(default=8000, env=\"CHROMADB_PORT\")\n\nconfig/settings.py:57\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:57: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    CHROMADB_PATH: str = Field(\n\nconfig/settings.py:63\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:63: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    OPENAI_API_KEY: Optional[str] = Field(default=None, env=\"OPENAI_API_KEY\")\n\nconfig/settings.py:64\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:64: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    ANTHROPIC_API_KEY: Optional[str] = Field(default=None, env=\"ANTHROPIC_API_KEY\")\n\nconfig/settings.py:65\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:65: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    OLLAMA_BASE_URL: str = Field(\n\nconfig/settings.py:71\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:71: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    DEFAULT_LLM_PROVIDER: str = Field(default=\"openai\", env=\"DEFAULT_LLM_PROVIDER\")\n\nconfig/settings.py:72\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:72: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    DEFAULT_MODEL: str = Field(default=\"gpt-5-chat-latest\", env=\"DEFAULT_MODEL\")\n\nconfig/settings.py:73\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:73: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    LLM_TEMPERATURE: float = Field(default=0.7, env=\"LLM_TEMPERATURE\")\n\nconfig/settings.py:74\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:74: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    LLM_MAX_TOKENS: int = Field(default=2000, env=\"LLM_MAX_TOKENS\")\n\nconfig/settings.py:77\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:77: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    TARGET_TEST_COVERAGE: float = Field(default=95.0, env=\"TARGET_TEST_COVERAGE\")\n\nconfig/settings.py:78\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:78: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    TARGET_PERFORMANCE_SCORE: float = Field(\n\nconfig/settings.py:82\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:82: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    TARGET_DOCUMENTATION_COVERAGE: float = Field(\n\nconfig/settings.py:86\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:86: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    TARGET_CODE_QUALITY_SCORE: float = Field(\n\nconfig/settings.py:90\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:90: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    TARGET_SECURITY_SCORE: float = Field(default=95.0, env=\"TARGET_SECURITY_SCORE\")\n\nconfig/settings.py:91\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:91: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    TARGET_USER_SATISFACTION: float = Field(\n\nconfig/settings.py:97\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:97: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    MAX_AGENT_RETRIES: int = Field(default=3, env=\"MAX_AGENT_RETRIES\")\n\nconfig/settings.py:98\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:98: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    AGENT_TIMEOUT_SECONDS: int = Field(default=300, env=\"AGENT_TIMEOUT_SECONDS\")\n\nconfig/settings.py:99\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:99: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    CHECKPOINT_INTERVAL_HOURS: int = Field(\n\nconfig/settings.py:105\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:105: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    PERSISTENCE_DIR: Path = Field(\n\nconfig/settings.py:109\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:109: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    LOGS_DIR: Path = Field(default=Path(\"logs\"), env=\"LOGS_DIR\")\n\nconfig/settings.py:112\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:112: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    SECRET_KEY: str = Field(\n\nconfig/settings.py:116\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:116: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    JWT_ALGORITHM: str = Field(default=\"HS256\", env=\"JWT_ALGORITHM\")\n\nconfig/settings.py:117\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:117: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    JWT_EXPIRATION_MINUTES: int = Field(\n\nconfig/settings.py:123\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:123: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    RATE_LIMIT_PER_MINUTE: int = Field(default=100, env=\"RATE_LIMIT_PER_MINUTE\")\n\nconfig/settings.py:125\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:125: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    @validator(\"CORS_ORIGINS\", pre=True)\n\nconfig/settings.py:132\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:132: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    @validator(\"PERSISTENCE_DIR\", \"LOGS_DIR\", pre=True)\n\nconfig/settings.py:13\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:13: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    class Settings(BaseSettings):\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n=========================== short test summary info ============================\nERROR tests/integration/test_multi_agent_coordination.py\n!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n======================== 41 warnings, 1 error in 0.72s =========================\n",
      "stderr": "/Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n  warnings.warn(\n",
      "command": "/Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/venv/bin/python -m pytest tests/integration/ -m integration -v"
    },
    "system": {
      "category": "system",
      "status": "FAILED",
      "duration": 20.1324520111084,
      "returncode": 5,
      "stdout": "============================= test session starts ==============================\nplatform darwin -- Python 3.9.6, pytest-8.1.1, pluggy-1.6.0 -- /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/venv/bin/python\ncachedir: .pytest_cache\nrootdir: /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder\nconfigfile: pytest.ini\nplugins: asyncio-0.23.5, anyio-4.12.0, langsmith-0.4.37, cov-4.1.0\nasyncio: mode=strict\ncollecting ... collected 38 items / 38 deselected / 0 selected\n\n=============================== warnings summary ===============================\nvenv/lib/python3.9/site-packages/jupyter_client/connect.py:22\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/venv/lib/python3.9/site-packages/jupyter_client/connect.py:22: DeprecationWarning: Jupyter is migrating its paths to use standard platformdirs\n  given by the platformdirs library.  To remove this warning and\n  see the appropriate new directories, set the environment variable\n  `JUPYTER_PLATFORM_DIRS=1` and then run `jupyter --paths`.\n  The use of platformdirs will be the default in `jupyter_core` v6\n    from jupyter_core.paths import jupyter_data_dir, jupyter_runtime_dir, secure_write\n\nvenv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n\nconfig/settings.py:19\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:19: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    DEBUG: bool = Field(default=False, env=\"DEBUG\")\n\nconfig/settings.py:22\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:22: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    API_HOST: str = Field(default=\"0.0.0.0\", env=\"API_HOST\")\n\nconfig/settings.py:23\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:23: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    API_PORT: int = Field(default=8000, env=\"API_PORT\")\n\nconfig/settings.py:24\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:24: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    API_WORKERS: int = Field(default=4, env=\"API_WORKERS\")\n\nconfig/settings.py:25\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:25: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    CORS_ORIGINS: List[str] = Field(\n\nconfig/settings.py:31\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:31: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    DATABASE_URL: str = Field(\n\nconfig/settings.py:35\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:35: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    DATABASE_POOL_SIZE: int = Field(default=20, env=\"DATABASE_POOL_SIZE\")\n\nconfig/settings.py:36\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:36: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    DATABASE_MAX_OVERFLOW: int = Field(default=10, env=\"DATABASE_MAX_OVERFLOW\")\n\nconfig/settings.py:39\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:39: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    REDIS_URL: str = Field(default=\"redis://localhost:6379/0\", env=\"REDIS_URL\")\n\nconfig/settings.py:40\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:40: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    REDIS_MAX_CONNECTIONS: int = Field(default=50, env=\"REDIS_MAX_CONNECTIONS\")\n\nconfig/settings.py:42\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:42: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    @validator(\"DATABASE_URL\", pre=True, always=True)\n\nconfig/settings.py:55\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:55: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    CHROMADB_HOST: str = Field(default=\"localhost\", env=\"CHROMADB_HOST\")\n\nconfig/settings.py:56\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:56: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    CHROMADB_PORT: int = Field(default=8000, env=\"CHROMADB_PORT\")\n\nconfig/settings.py:57\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:57: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    CHROMADB_PATH: str = Field(\n\nconfig/settings.py:63\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:63: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    OPENAI_API_KEY: Optional[str] = Field(default=None, env=\"OPENAI_API_KEY\")\n\nconfig/settings.py:64\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:64: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    ANTHROPIC_API_KEY: Optional[str] = Field(default=None, env=\"ANTHROPIC_API_KEY\")\n\nconfig/settings.py:65\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:65: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    OLLAMA_BASE_URL: str = Field(\n\nconfig/settings.py:71\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:71: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    DEFAULT_LLM_PROVIDER: str = Field(default=\"openai\", env=\"DEFAULT_LLM_PROVIDER\")\n\nconfig/settings.py:72\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:72: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    DEFAULT_MODEL: str = Field(default=\"gpt-5-chat-latest\", env=\"DEFAULT_MODEL\")\n\nconfig/settings.py:73\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:73: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    LLM_TEMPERATURE: float = Field(default=0.7, env=\"LLM_TEMPERATURE\")\n\nconfig/settings.py:74\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:74: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    LLM_MAX_TOKENS: int = Field(default=2000, env=\"LLM_MAX_TOKENS\")\n\nconfig/settings.py:77\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:77: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    TARGET_TEST_COVERAGE: float = Field(default=95.0, env=\"TARGET_TEST_COVERAGE\")\n\nconfig/settings.py:78\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:78: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    TARGET_PERFORMANCE_SCORE: float = Field(\n\nconfig/settings.py:82\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:82: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    TARGET_DOCUMENTATION_COVERAGE: float = Field(\n\nconfig/settings.py:86\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:86: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    TARGET_CODE_QUALITY_SCORE: float = Field(\n\nconfig/settings.py:90\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:90: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    TARGET_SECURITY_SCORE: float = Field(default=95.0, env=\"TARGET_SECURITY_SCORE\")\n\nconfig/settings.py:91\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:91: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    TARGET_USER_SATISFACTION: float = Field(\n\nconfig/settings.py:97\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:97: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    MAX_AGENT_RETRIES: int = Field(default=3, env=\"MAX_AGENT_RETRIES\")\n\nconfig/settings.py:98\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:98: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    AGENT_TIMEOUT_SECONDS: int = Field(default=300, env=\"AGENT_TIMEOUT_SECONDS\")\n\nconfig/settings.py:99\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:99: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    CHECKPOINT_INTERVAL_HOURS: int = Field(\n\nconfig/settings.py:105\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:105: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    PERSISTENCE_DIR: Path = Field(\n\nconfig/settings.py:109\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:109: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    LOGS_DIR: Path = Field(default=Path(\"logs\"), env=\"LOGS_DIR\")\n\nconfig/settings.py:112\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:112: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    SECRET_KEY: str = Field(\n\nconfig/settings.py:116\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:116: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    JWT_ALGORITHM: str = Field(default=\"HS256\", env=\"JWT_ALGORITHM\")\n\nconfig/settings.py:117\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:117: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    JWT_EXPIRATION_MINUTES: int = Field(\n\nconfig/settings.py:123\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:123: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'env'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    RATE_LIMIT_PER_MINUTE: int = Field(default=100, env=\"RATE_LIMIT_PER_MINUTE\")\n\nconfig/settings.py:125\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:125: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    @validator(\"CORS_ORIGINS\", pre=True)\n\nconfig/settings.py:132\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:132: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    @validator(\"PERSISTENCE_DIR\", \"LOGS_DIR\", pre=True)\n\nconfig/settings.py:13\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/config/settings.py:13: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    class Settings(BaseSettings):\n\ntests/system/test_api_performance.py:308\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/tests/system/test_api_performance.py:308: PytestUnknownMarkWarning: Unknown pytest.mark.performance - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.performance\n\ntests/system/test_api_performance.py:461\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/tests/system/test_api_performance.py:461: PytestUnknownMarkWarning: Unknown pytest.mark.performance - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.performance\n\ntests/system/test_api_performance.py:462\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/tests/system/test_api_performance.py:462: PytestUnknownMarkWarning: Unknown pytest.mark.benchmark - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.benchmark\n\ntests/system/test_database_performance.py:426\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/tests/system/test_database_performance.py:426: PytestUnknownMarkWarning: Unknown pytest.mark.performance - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.performance\n\ntests/system/test_database_performance.py:427\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/tests/system/test_database_performance.py:427: PytestUnknownMarkWarning: Unknown pytest.mark.database - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.database\n\ntests/system/test_e2e_calculator_build.py:12\n  /Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/tests/system/test_e2e_calculator_build.py:12: PytestUnknownMarkWarning: Unknown pytest.mark.e2e - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.e2e\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n===================== 38 deselected, 47 warnings in 0.43s ======================\n",
      "stderr": "/Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n  warnings.warn(\n",
      "command": "/Users/apple/Library/Mobile Documents/com~apple~CloudDocs/SProjects/myagent-continuous-ai-builder/venv/bin/python -m pytest tests/system/ -m system -v"
    }
  },
  "recommendations": [
    "Fix unit test failures before proceeding with integration testing",
    "Review agent coordination and API integration issues",
    "Implement missing test categories: e2e, performance, usability",
    "Improve test coverage in integration tests",
    "Improve test coverage in system tests"
  ]
}
